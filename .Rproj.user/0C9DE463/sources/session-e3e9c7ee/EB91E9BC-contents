---
title: "ANOVA"
author: "C√©cile Mazon"
date: '2022-11-08'
output: 
  html_document:
    toc: TRUE
    toc_depth: 3
    theme: cerulean
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE)
options(tibble.width = Inf) # displays all columns.
options(tibble.print_max = Inf) # to show all the rows.
library(broom)
library(car)
library(emmeans)
library(rstatix)
library(datarium)
library(tidyverse)
library(ggpubr)
library(psych)
library(GGally)
```

Ce document est r√©serv√© √† l'usage priv√© des √©tudiants du Master Sciences Cognitives et Ergonomie, parcours TECH, en compl√©ment des cours dispens√©s. Il ne doit pas √™tre diffus√© en dehors de cet usage.

L'objectif de ce document est de fournir un r√©sum√© du cours et un mod√®le de document Rmarkdown.

**Remarque importante** : Pour chaque proc√©dure, je propose √† chaque fois plusieurs alternatives de code. En g√©n√©ral, vous avez une version de code utilisant les fonctions "classiques" de R, et une version utilisant l'environnement "tidyverse", qui √† mon sens, propose des syntaxes plus lisibles et plus faciles √† utiliser (une fois qu'on s'y est habitu√© ;-) )

# Introduction

Les analyses de variance permettent de comparer plusieurs moyennes pour d√©terminer si elles sont significativement diff√©rentes ou non.

Le principe est de comparer le comportement d'une variable quantitative (la VD) en fonction des modalit√©s d'une ou plusieurs variables qualitatives (VI).

Il existe plusieurs tests permettant de r√©aliser une analyse de variance. Le choix d√©pendra de plusieurs crit√®res :

1.  **La normalit√© des distributions.** On utilisera des tests param√©triques lorsque les distributions sont normalement distribu√©es (*i.e.*, les donn√©es suivent une loi Normale)
2.  **Le nombre de modalit√©s √† comparer.** On n'utilisera pas les m√™mes tests lorsqu'on compare deux moyennes vs. plus de deux moyennes
3.  **Le type de facteur (VI).** Les analyses de variance sont diff√©rentes si on compare des groupes ind√©pendants (VI intergroupe) ou des groupes dits appari√©s (VI intragroupe).

Quelle que soit l'analyse utilis√©e, on suivra plus ou moins la m√™me proc√©dure :

1.  Nettoyage et pr√©paration des donn√©es
2.  V√©rification des conditions d'application
3.  Statistiques descriptives et repr√©sentations graphiques
4.  R√©alisation du test statistique
5.  Tests post-hoc (le cas √©ch√©ant)

# Comparaison de plus de deux moyennes

Le test ANOVA est utilis√© lorsque vous souhaitez comparer plus de deux moyennes.

L'ANOVA peut √™tre r√©alis√©e avec **1, 2 ou 3 facteur(s)**, et chacun de ces facteurs peut √™tre **intergroupe** (*between-subject*) ou **intragroupe** (*within-subject*).

En fonction du type de facteur(s) employ√©s dans l'analyse, on distinguera :

-   Les **ANOVA inter-sujets**, qui ne contiennent que des facteurs intergroupes

-   Les **ANOVA √† mesures r√©p√©t√©es (intra-sujets)** qui ne contiennent que des facteurs intragroupes

-   Les **ANOVA mixtes** qui contiennent les deux types de facteurs.

Cette distinction est importante parce que c'est ce qui va d√©finir les conditions d'application de l'analyse.

Pour ce qui est de la r√©alisation de l'analyse, elle se d√©roule selon les m√™mes √©tapes que pour le test t des Student, √† la diff√©rence qu'on ajoutera en g√©n√©ral **une phase de tests post-hoc**. Ces derniers consistent √† faire des comparaisons de moyennes deux √† deux pour examiner en d√©tail les effets globaux et/ou d'interaction mis en √©vidence dans l'analyse.

## L'analyse de variance (ANOVA) √† 1 facteur

### ANOVA √† 1 facteur inter-sujet

**L'ANOVA √† 1 facteur inter-sujet** (*One-way between-subject ANOVA*) permet de comparer les moyennes issues de plus de deux √©chantillons non-li√©s (i.e., compos√©s d'individus diff√©rents). Il est utilis√© dans le cas o√π vous avez une exp√©rience avec une **VI intergroupe √† plus de 2 modalit√©s**.

**Jeu de donn√©es utilis√©**

Pour l'exemple, on va prendre le jeu de donn√©es `PlantGrowth`, qui contient le poids de plantes en fonction du traitement administr√©.

```{r}
head(PlantGrowth)

#Ajout d'une colonne avec un identifiant
plant <- cbind(ID = 1:30, PlantGrowth)
plant <- transform(plant, ID = as.factor(ID))
```

Ce jeu de donn√©es contient deux variables :

-   `weight` : le poids des plantes en grammes (VD)

-   `group` : la variable de regroupement (VI intergroupe) √† 3 modalit√©s : Contr√¥le, Traitement 1, Traitement 2

La variable `group` est **une variable intergroupe**, puisque chaque individu n'appartient qu'√† un seul groupe (ils ne passent donc qu'une modalit√© de la variable).

On va donc r√©aliser une ANOVA √† 1 facteur inter-sujet pour √©valuer l'effet du traitement sur la prise de poids des plantes.

```{r}
str(plant)
glimpse(plant)
```

#### 1. V√©rification des conditions d'application

<u> Conditions d'application :</u> Elles sont identiques √† celles d'un test t pour √©ch. ind√©pendants

1.  **Ind√©pendance des observations** : Chaque individu appartient √† un seul groupe. Il n'y a pas de relations entre les observations de chaque groupe. Cette condition revient √† s'assurer que la VI est bien intergroupe.

2.  **Absence de valeurs aberrantes.** Les donn√©es de chaque groupe ne doivent pas contenir de valeurs aberrantes.

3.  **Normalit√© de la distribution.** Les donn√©es de chaque groupe sont distribu√©es normalement.

4.  **Homog√©n√©it√© des variances.** Les variances de tous les groupes sont homog√®nes.

##### Valeurs aberrantes

Comme pour le t-test, on va examiner la pr√©sence de ces valeurs dans les donn√©es de chaque groupe s√©par√©ment.

```{r}
#Boite √† moustaches
ggboxplot(plant, x = "group", y = "weight", 
          add = "jitter", bxp.errorbar = TRUE)

#Algorithme
plant %>%
  group_by(group) %>%
  identify_outliers(weight)

```

**Interpr√©tation :** Les valeurs aberrantes ne sont pas extr√™mes, on va donc les conserver pour l'analyse.

##### Normalit√© des distributions

On examine la normalit√© de la distribution dans chaque groupe s√©par√©ment.

```{r, fig.show='hold', fig.asp=1, fig.width=4.5}
#Diagramme QQ
ggqqplot(plant, x = "weight", color = "group")

ggqqplot(plant, x = "weight", facet.by = "group")
```

```{r}
#En utilisant la fonction by() --> Syntaxe : by(VD, VI, test)
by(plant$weight, plant$group, shapiro.test)

#Alternative avec rstatix
plant %>%
  group_by(group) %>%
  shapiro_test(weight)
```

**Interpr√©tation :** La distribution dans chaque groupe est bien normale (tests de Shapiro, p \> .05), on peut donc continuer avec notre ANOVA.

Lorsque les donn√©es ne sont pas normales, on fait comme pour le t-test : soit on garde l'ANOVA parce qu'elle peut r√©sister √† cette non-normalit√©, soit on utilise une alternative non-param√©trique, soit on transforme nos donn√©es.

------------------------------------------------------------------------

**Il existe une autre mani√®re d'examiner la normalit√© de la distribution en analysant les r√©sidus du** **mod√®le** : On utilise le diagramme QQ et le test de Shapiro, non pas sur chaque groupe s√©par√©ment, mais sur les r√©sidus du mod√®le ANOVA.\
Cette approche peut √™tre pratique lorsque vos √©chantillons sont petits.

**Qu'est-ce qu'un r√©sidu ?** Lorsqu'on r√©alise une ANOVA, on construit un mod√®le lin√©aire de notre ph√©nom√®ne. Autrement dit, on utilise les valeurs de notre/nos VI pour pr√©dire la valeur de notre VD. Un mod√®le n'√©tant jamais parfait, la pr√©diction de la valeur de la VD implique une **erreur de pr√©diction**. Les r√©sidus d'une ANOVA (ou d'une r√©gression) d√©signent l'ensemble des erreurs de pr√©diction pour chaque observation de l'analyse. On peut aussi d√©finir les r√©sidus comme "la variance non expliqu√©e par le mod√®le".

```{r}
# Cr√©ation du mod√®le lin√©aire
model <- lm(weight ~ group, data = plant)

# QQ plot
ggqqplot(residuals(model))

#Test de Shapiro
shapiro_test(residuals(model))
```

##### Homog√©n√©it√© des variances

Pour v√©rifier si les variances sont homog√®nes, on va utiliser le **test de Levene**. Comme pour les tests de normalit√©, on estimera que les variances sont homog√®nes lorsque la p-value est sup√©rieure √† .05, puisque son hypoth√®se nulle est que les variances ne sont pas diff√©rentes.

```{r}
# Fonction leveneTest (librairie car)
leveneTest(weight ~ group, plant)

# Fonction levene_test (librairie rstatix)
levene_test(plant, weight ~ group)
```

**Interpr√©tation** : La p-value √©tant sup√©rieure √† .05, on peut conclure que les variances sont homog√®nes.

**Que faire si les variances ne sont pas homog√®nes ?\
**La non-homog√©n√©it√© des variances n'est pas un frein √† l'utilisation d'un test ANOVA. Il existe une correction qui permet d'utiliser le test ANOVA en cas d'h√©t√©rog√©n√©it√© des variances : **le test ANOVA avec correction de Welch.**\
Il suffira de pr√©ciser dans les arguments de la fonction `welch_anova_test()`.

#### 2. Statistiques descriptives et repr√©sentation graphique des donn√©es.

**Statistiques descriptives**

```{r mice stats-desc4}
# Fonction de base pour obtenir des indicateurs statistiques
summary(plant)

# Fonctions renvoyant des donn√©es plus compl√®tes
  #Librarie rstatix
    #Au global
get_summary_stats(plant, type = "common")

    #En fonction des modlit√©s de la variable "supp"
plant %>%
  group_by(group) %>%
  get_summary_stats(weight)

  #Librarie psych
describeBy(weight ~ group, data = plant)
```

On observe d'ores et d√©j√† que le poids moyen est de 5.03 g (SD = 0.58) dans le groupe Contr√¥le, de 4.66 g (SD = 0.79) pour le groupe Trt1 et de 5.53 g (SD = 0.44) dans le groupe Trt2.

**Repr√©sentation graphique**

Quelques exemples de repr√©sentation graphique

```{r, fig.show='hold', fig.asp=1, fig.width= 3}
ggline(plant, plot_type = "b", add = "mean_se", 
       x = "group", y = "weight", linetype = 2, 
       xlab = FALSE, ylab = "Poids des plantes (en g)")

ggboxplot(plant, x = "group", y = "weight", add = "jitter",
          bxp.errorbar = TRUE, xlab = FALSE, color = "group",
          ylab = "Poids des plantes (en g)", legend = "none")

ggbarplot(plant, x = "group", y = "weight", add = "mean_se", 
          palette = "Set1", fill = "group", ylab = "Poids des plantes (en g)",
          legend = "none")
```

#### 3. R√©alisation de l'ANOVA

Nos conditions d'application √©tant v√©rifi√©es, nous pouvons r√©aliser l'ANOVA √† 1 facteur. Nous souhaitons savoir si le poids des plantes est diff√©rent pour le groupe contr√¥le vs. trt1 vs. trt2.

Version avec la fonction `aov()`

```{r aov test}

#Fonction aov (librairie stats)
res.plant <- aov(weight ~ group, plant)
summary(res.plant)


```

Version avec la fonction `anova_test()` de la librairie `rstatix` :

```{r}
#Fonction anova_test (librairie rstatix)
  # Version avec la formule
res.plant <- anova_test(plant, weight ~ group, detailed = TRUE)
get_anova_table(res.plant)

  # Version avec les arguments
res.plant <- anova_test(plant, dv = weight, between = group, detailed = TRUE)
get_anova_table(res.plant)
```

**Remarque**. Je vous conseille d'utiliser plut√¥t la fonction `anova_test()`, qui est beaucoup plus facile √† utiliser, gr√¢ce √† la possibilit√© d'indiquer vos diff√©rentes variables par des arguments. Nous verrons dans les sections suivantes que la fonction `aov()` peut √™tre difficile √† utiliser dans certains cas.

**Interpr√©tation de l'analyse (1) :**

En observant les r√©sultats du test ANOVA, on voit que pour **l'effet principal du groupe, la p-value est inf√©rieure √† .05**. On a donc un effet significatif de la condition, reste √† savoir si toutes les moyennes sont diff√©rentes entre elles ou non.

**La taille d'effet pour l'ANOVA nous est donn√©e par l'indicateur eta^2^**, qui s'interpr√®te tr√®s simplement : $eta^2 = 0.26$ signifie que 26% de la variation du poids est attribuable aux conditions de traitement.

[Passons maintenant aux **tests post-hoc** :]{.underline}

Ils consistent √† faire **un ensemble de test-t entre les moyennes de chaque modalit√© deux √† deux**, pour d√©terminer si elles sont significativement diff√©rentes les unes des autres. Comme il y a de multiples tests r√©alis√©s, on applique **une correction de la p-value**. Les tests les plus courants avec l'ANOVA sont les tests de Tukey HSD ou les comparaison avec correction de Bonferroni.

```{r}
# Comparaisons deux √† deux avec la correction de Tukey
pwc.plant <- tukey_hsd(plant,weight ~ group)
pwc.plant

# Comparaisons deux √† deux avec la correction de Bonferroni
pwc.plant <- pairwise_t_test(plant, weight ~ group, p.adjust.method = "bonferroni")
pwc.plant

```

**Remarque.** Si les variances √©taient h√©t√©rog√®nes et que vous avez utilis√© une **Anova de Welch**, vous ne pouvez pas utiliser les fonctions ci-dessus pour les tests post-hoc. Vous pouvez n√©anmoins utiliser le **test de Games-Howell** : `games_howell_test(plant, weight ~ group)`.

**Interpr√©tation de l'analyse (2) :**

Les tests post-hoc nous permettent de dire que **seule la diff√©rence entre trt1 et trt2 est significative** (les autres ne passent pas le seuil).

#### 4. Reporter les r√©sultats

Pour reporter les r√©sultats d'une analyse statistique :

-   On d√©crit les diff√©rences observ√©es et on donne le r√©sultat de l'analyse statistique avec la formule r√©capitulative dans le texte :
    -   Expliquer que l'effet principal du groupe est significatif : $F(2, 27) = 4.846, p < 0.05, ùúÇ^2 = 0.26$.

    -   La diff√©rence n'est significative qu'entre trt1 et trt2 (p. adj. \< .05). Cela signifie que le Traitement 2 produit de meilleurs r√©sultats que le Traitement 1, mais qu'aucun des deux traitements ne produit de meilleurs effets que la condition Contr√¥le.
-   On peut aussi reporter cette information dans un tableau d√©crivant les donn√©es (par ex : moyenne, ecart-type, r√©sultat ANOVA + post-hoc).
-   Une repr√©sentation graphique sur laquelle on indique les diff√©rences significatives est aussi appr√©ci√©e (ici, ce n'est pas le cas, mais on le verra plus tard).

```{r, fig.show='hold', fig.asp=1, fig.width= 4.5}

# Avec des boxplot et la fonction geom_bracket() qui permet de d√©finir manuellement les marques pour les diff√©rences significatives
ggboxplot(plant, x = "group", y = "weight", 
          bxp.errorbar = TRUE, xlab = FALSE, color = "group",
          ylab = "Poids des plantes (en g)", 
          ylim = c(3.5, 7), legend = "none") +
  geom_bracket(
    xmin = "trt1", xmax = "trt2", y.position = 6.5,
    label = "*", tip.length = c(0.1, 0.02), label.size = 6
  )

# Avec des barplots et la fonction stat_pvalue_manuel() qui permet de d√©finir automatiquement les marques pour les diff√©rences significatives
pwc.plant <- pwc.plant %>% add_xy_position(x = "group")

ggbarplot(plant, x = "group", y = "weight", add = "mean_se", 
          palette = "Set1", fill = "group", 
          xlab = "Groupe", ylab = "Poids des plantes (en g)",
          legend = "none")  +
  stat_pvalue_manual(pwc.plant, hide.ns = TRUE, y.position = 6)
```

### ANOVA √† 1 facteur intra-sujet (mesures r√©p√©t√©es)

**L'ANOVA √† 1 facteur intra-sujet** (*One-way within-subject ANOVA*) permet de comparer les moyennes issues de plus de deux √©chantillons appari√©s (i.e., compos√©s des m√™mes individus). Il est utilis√© dans le cas o√π vous avez une exp√©rience avec une **VI intragroupe √† plus de 2 modalit√©s**.

**Jeu de donn√©es utilis√©**

On va prendre le jeu de donn√©es `selfesteem`, qui contient le score √† un questionnaire d'estime de soi de 10 individus au cours du temps (trois temps de mesure : T1, T2, T3).

```{r}
head(selfesteem)
```

Ce jeu de donn√©es contient quatre variables :

-   `id` : num√©ro d'identification de l'individu

-   `t1`, `t2`, `t3` : score au 1er, au 2eme et au 3eme temps de mesure

La variable `time` (que nous allons cr√©er juste apr√®s) est **une variable intragroupe**, puisque tous les individus passent toutes ses modalit√©s (t1, t2, t3). Autrement dit, on mesure le score d'estime de soi des individus aux trois temps de mesure (3 mesures r√©p√©t√©es).

On va donc r√©aliser une ANOVA √† 1 facteur intra-sujet pour √©valuer l'effet du temps sur le score d'estime de soi

```{r}
str(selfesteem)
glimpse(selfesteem)
```

**Pr√©paration du jeu de donn√©es**

Comme pour le t-test pour √©chantillons appari√©s, la r√©alisation de l'analyse implique de cr√©er un fichier avec une variable de regroupement et une seule colonne contenant la VD. On utilise √† nouveau la fonction `gather()`.

La colonne `id` est essentielle pour une analyse √† mesures r√©p√©t√©es, afin que le test puisse tenir compte de la variation intra-sujet (au sein d'un m√™me individu). Cette colonne doit √™tre transform√©e en facteur.

```{r}
selfesteem <- transform(selfesteem, id = as.factor(id))

selfesteem.long <- selfesteem %>%
  gather(key = "time", value = "score", t1, t2, t3, factor_key = TRUE)

str(selfesteem.long)
```

#### 1. V√©rification des conditions d'application

<u> Conditions d'application :</u> Elles sont identiques √† celles d'un test t pour √©ch. ind√©pendants

1.  **Appariement des observations** : Chaque individu a une mesure pour chaque modalit√© de la VI ; il y a autant de mesures par individu que de modalit√©s dans la variable. Cette condition revient √† s'assurer que la VI est bien intragroupe.

2.  **Absence de valeurs aberrantes.** Les donn√©es de chaque groupe ne doivent pas contenir de valeurs aberrantes.

3.  **Normalit√© de la distribution.** Les donn√©es de chaque groupe sont distribu√©es normalement.

4.  **Sph√©ricit√© des variances.** L'hypoth√®se de sph√©ricit√© signifie que les variances des diff√©rences entre les conditions sont homog√®nes.

##### Valeurs aberrantes

On examine la pr√©sence de ces valeurs dans les donn√©es de chaque groupe s√©par√©ment.

```{r}
#Boite √† moustaches
ggboxplot(selfesteem.long, x = "time", y = "score", 
          add = "jitter", bxp.errorbar = TRUE)

#Algorithme
selfesteem.long %>%
  group_by(time) %>%
  identify_outliers(score)

```

**Interpr√©tation :** Les valeurs aberrantes ne sont pas extr√™mes, on va donc les conserver pour l'analyse.

##### Normalit√© des distributions

On examine la normalit√© de la distribution dans chaque groupe s√©par√©ment.

```{r, fig.show='hold', fig.asp=1, fig.width=4.5}
#Diagramme QQ
ggqqplot(selfesteem.long, x = "score", color = "time")

ggqqplot(selfesteem.long, x = "score", facet.by = "time")
```

```{r}
# On peut utiliser le fichier original pour faire un test par colonne
shapiro.test(selfesteem$t1)
shapiro.test(selfesteem$t2)
shapiro.test(selfesteem$t3)

#Ou utiliser la fonction by() sur selfesteem.long 
# Syntaxe : by(selfesteem.long$score, selfesteem.long$time, shapiro.test)

#Alternative avec rstatix
selfesteem.long %>%
  group_by(time) %>%
  shapiro_test(score)
```

**Interpr√©tation :** La distribution dans chaque groupe est bien normale (tests de Shapiro, p \> .05), on peut donc continuer avec notre ANOVA.

**Lorsque les donn√©es ne sont pas normales,** on fait comme pour le t-test : soit on garde l'ANOVA parce qu'elle peut r√©sister √† cette non-normalit√©, soit on utilise une alternative non-param√©trique, soit on transforme nos donn√©es.

##### Sph√©ricit√©

Pour v√©rifier l'hypoth√®se de sph√©ricit√©, on va utiliser le **test de sph√©ricit√© de Mauchly**. Ce test consiste √† √©valuer si la variance des diff√©rences entre toutes les conditions sont homog√®nes.

En utilisant la fonction `anova_test()` de rstatix, le test de sph√©ricit√© est compris dans la proc√©dure. On verra dans la section de r√©alisation de l'analyse comment obtenir le r√©sultat du test de Mauchly.

**Que faire si la sph√©ricit√© n'est pas respect√©e ?\
**L√† encore, pas de panique, on peut quand m√™me utiliser l'ANOVA, en appliquant des corrections. La plus courante est la **correction de Greenhouse-Geisser (GG)**, qu'on appliquera aux facteurs concern√©s par la violation de la sph√©ricit√©.

En utilisant les fonctions propos√©es par `rstatix`, cette correction sera appliqu√©e en ajoutant l'argument `correction = "auto"` dans la fonction `get_anova_table()`.

#### 2. Statistiques descriptives et repr√©sentation graphique des donn√©es.

**Statistiques descriptives**

```{r}
# Fonction de base pour obtenir des indicateurs statistiques
summary(selfesteem.long)
summary(selfesteem)

# Fonctions renvoyant des donn√©es plus compl√®tes
  #Librarie rstatix
    #Au global
get_summary_stats(selfesteem.long, type = "common")

    #En fonction des modlit√©s de la variable "supp"
selfesteem.long %>%
  group_by(time) %>%
  get_summary_stats(score)

  #Librarie psych
describeBy(score ~ time, data = selfesteem.long)
```

On observe d'ores et d√©j√† que le score moyen est de 3.14 (SD = 0.55) √† T1, de 4.93 (SD = 0.86) √† T2 et de 7.64 (SD = 1.14) √† T3.

**Repr√©sentation graphique**

Quelques exemples de repr√©sentation graphique

```{r, fig.show='hold', fig.asp=1, fig.width= 3}
ggline(selfesteem.long, plot_type = "b", add = "mean_se", 
       x = "time", y = "score", linetype = 2,
       xlab = FALSE, ylab = "Score d'estime de soi")

ggboxplot(selfesteem.long, x = "time", y = "score", add = "jitter",
          bxp.errorbar = TRUE, xlab = FALSE, color = "time",
          ylab = "Score d'estime de soi", legend = "none")

ggbarplot(selfesteem.long, x = "time", y = "score", add = "mean_se", 
          palette = "Set1", fill = "time", ylab = "Score d'estime de soi",
          legend = "none")
```

#### 3. R√©alisation de l'ANOVA

Nos conditions d'application √©tant v√©rifi√©es, nous pouvons r√©aliser l'ANOVA √† 1 facteur intra-sujet. Nous souhaitons savoir si le score d'estime de soi est diff√©rent entre T1, T2 et T3.

Version avec la fonction `aov()` - Non recommand√©e

```{r}
#Fonction aov (librairie stats)
res.se <- aov(score ~ time + Error(id/time), selfesteem.long)
summary(res.se)
```

Version avec la fonction `anova_test()` de la librairie `rstatix` :

```{r}
#Fonction anova_test (librairie rstatix)
  # Version avec la formule
res.se <- anova_test(selfesteem.long, score ~ time + Error(id/time), detailed = TRUE)
res.se
get_anova_table(res.se, correction = "auto")

  # Version avec les arguments
res.se <- anova_test(selfesteem.long, dv = score, within = time, wid = id, detailed = TRUE)
res.se
get_anova_table(res.se, correction = "auto")
```

**Remarque**. Je vous conseille d'utiliser plut√¥t la fonction `anova_test()`, qui est beaucoup plus facile √† utiliser, gr√¢ce √† la possibilit√© d'indiquer vos diff√©rentes variables par des arguments. Nous verrons dans les sections suivantes que la fonction `aov()` peut √™tre difficile √† utiliser dans certains cas.

**Interpr√©tation de l'analyse (1) :**

En observant les r√©sultats du test ANOVA, on voit que pour **l'effet principal du temps, la p-value est inf√©rieure √† .05**. On a donc un effet significatif de la condition, reste √† savoir si toutes les moyennes sont diff√©rentes entre elles ou non.

**La taille d'effet pour l'ANOVA nous est donn√©e par l'indicateur eta^2^**, qui s'interpr√®te tr√®s simplement : $eta^2 = 0.83$ signifie que 83% de la variation du score est attribuable aux conditions de traitement.

[Passons maintenant aux **tests post-hoc** :]{.underline}

Ils consistent √† faire **un ensemble de test-t entre les moyennes de chaque modalit√© deux √† deux**, pour d√©terminer si elles sont significativement diff√©rentes les unes des autres. Comme il y a de multiples tests r√©alis√©s, on applique **une correction de la p-value**.

Les tests les plus courants avec l'ANOVA √† 1 facteur inter-sujet sont les tests de Tukey HSD ou les comparaisons avec correction de Bonferroni.

```{r}
# Comparaisons deux √† deux avec la correction de Bonferroni
pwc.se <- pairwise_t_test(selfesteem.long, score ~ time, paired = TRUE, p.adjust.method = "bonferroni")
pwc.se

```

**Interpr√©tation de l'analyse (2) :**

Les tests post-hoc nous permettent de dire que **les trois diff√©rences sont significatives**. On peut donc conclure que le score s'am√©liore significativement entre T1 et T2, entre T2 et T3 et entre T1 et T3.

#### 4. Reporter les r√©sultats

Pour reporter les r√©sultats d'une analyse statistique :

-   On d√©crit les diff√©rences observ√©es et on donne le r√©sultat de l'analyse statistique avec la formule r√©capitulative dans le texte :
    -   Expliquer que l'effet principal du groupe est significatif : $F(2, 18) = 55.469, p < 0.001, ùúÇ^2 = 0.83$.

    -   Toutes les diff√©rences entre les modalit√©s sont significatives (p. adj. \< .001). On a donc T1 \< T2 \< T3, ce qui signifie une am√©lioration de l'estime de soi √† chaque temps de mesure.
-   On peut aussi reporter cette information dans un tableau d√©crivant les donn√©es (par ex : moyenne, ecart-type, r√©sultat ANOVA + post-hoc).
-   Une repr√©sentation graphique sur laquelle on indique les diff√©rences significatives est aussi appr√©ci√©e (ici, ce n'est pas le cas, mais on le verra plus tard).

```{r, fig.show='hold', fig.asp=1, fig.width= 4.5}

# Avec des boxplot et la fonction geom_bracket() qui permet de d√©finir manuellement les marques pour les diff√©rences significatives
ggboxplot(selfesteem.long, x = "time", y = "score",
          bxp.errorbar = TRUE, xlab = FALSE, color = "time",
          ylab = "Score d'estime de soi", legend = "none",
          ylim = c(1.5, 13)) +
  geom_bracket(
    xmin = c("t1", "t2", "t1"), xmax = c("t2", "t3", "t3"), y.position = c(8, 11.5, 12.5),
    label = "***", tip.length = c(0.2, 0.05), label.size = 5,
  )
# Avec un line graph et la fonction stat_pvalue_manuel() qui permet de d√©finir automatiquement les marques pour les diff√©rences significatives
pwc.se <- pwc.se %>% add_xy_position(x = "time", fun = "mean_se")

ggline(selfesteem.long, plot_type = "b", add = "mean_se", 
       x = "time", y = "score", linetype = 2,
       xlab = FALSE, ylab = "Score d'estime de soi") +
  stat_pvalue_manual(pwc.se, hide.ns = TRUE, y.position = c(5.5, 8.5, 8.2), tip.length = c(0.2, 0.01))
```

### Alternatives non-param√©triques pour les analyses √† 1 facteur

#### Le test de Kruskal-Wallis pour les VI intergroupe

**Le test de Kruskal-Wallis est l'alternative non-param√©trique pour l'ANOVA √† 1 facteur inter-sujet** (VI intergroupe).

Pour r√©aliser le test de Kruskal-Wallis, on va r√©utiliser le jeu de donn√©es `plant`, qu'on avait utilis√© pour l'ANOVA √† 1 facteur inter-sujet.

On r√©alise la m√™me proc√©dure qu'une ANOVA. Il n'y a pas de conditions d'application √† v√©rifier n√©anmoins. Ci-dessous, je pr√©sente uniquement la r√©alisation du test de Kruskal-Wallis et les test post-hoc.

```{r}
resKW <- plant %>%
  kruskal_test(weight ~ group)
resKW

# Taille d'effet - indicateur eta2
plant %>% kruskal_effsize(weight ~group)

#Comparaisons deux √† deux avec le test de Wilcoxon pour ech. ind.
pwcKW <- plant %>%
  wilcox_test(weight ~ group, p.adjust.method = "bonferroni")
pwcKW
```

Pour **rapporter l'analyse**, on √©crira : $œá^2 (2) = 7.99, p < .05, Œ∑^2 = .22$ (au lieu du F de l'Anova), et on pr√©cisera que la diff√©rence est significative uniquement entre trt1 et trt2 (p adj. \< .05).

#### Le test de Friedman pour les VI intragroupe

**Le test de Friedman est l'alternative non-param√©trique pour l'ANOVA √† 1 facteur intra-sujet** (VI intragroupe).

Pour r√©aliser le test de Friedman, on va r√©utiliser le jeu de donn√©es `selfesteem.long`, qu'on avait utilis√© pour l'ANOVA √† 1 facteur intra-sujet.

On r√©alise la m√™me proc√©dure qu'une ANOVA. Il n'y a pas de conditions d'application √† v√©rifier n√©anmoins. Ci-dessous, je pr√©sente uniquement la r√©alisation du test de Friedman et les test post-hoc.

**Remarque**. La syntaxe pour le test de Friedman est l√©g√®rement diff√©rente de celle de l'ANOVA √† 1 facteur intra-sujet. Pour le test de Friedman, la syntaxe de la formule est `VD ~ VI|id` (avec une barre verticale entre la VI et les identifiants).

```{r}
resF <- selfesteem.long %>%
  friedman_test(score ~ time|id)
resF

# Taille d'effet - indicateur Kendall's W
selfesteem.long %>% friedman_effsize(score ~ time|id)

#Comparaisons deux √† deux avec le test de Wilcoxon pour ech. app. (ajouter l'argument paired = TRUE)

pwcF <- selfesteem.long %>%
  wilcox_test(score ~ time, paired = TRUE, p.adjust.method = "bonferroni")
pwcF
```

**Pour rapporter l'analyse**, on √©crira : $œá^2 (2) = 18.2, p < .001, W = .91$ (au lieu du F de l'Anova), et on pr√©cisera que les diff√©rences entre toutes les modalit√©s sont significatives (p adj. \< .05).

## L'analyse de variance (ANOVA) √† 2 facteurs

Lorsqu'on souhaite r√©aliser une comparaison de moyennes avec deux VI, on va avoir trois cas possibles :

-   ANOVA √† 2 facteurs inter-sujets

-   ANOVA √† 2 facteurs intra-sujets

-   ANOVA mixtes (une VI intergroupe et une VI intragroupe)

**Remarque.** Le m√™me principe s'applique pour les ANOVA √† 3 facteurs : a) ANOVA √† 3 facteurs inter-sujets, b) ANOVA √† 3 facteurs intra-sujets, et c) ANOVA mixtes (2 facteurs inter-sujets et 1 facteur intra-sujet ou 1 facteur inter-sujet et 2 facteurs intra-sujet). Les conditions d'application sont les m√™mes que pour les ANOVA √† 2 facteurs, et la proc√©dure est quasi-identique.

Des exemples d'ANOVA √† trois facteurs sont disponibles sur le site Datanovia (vous y retrouverez aussi tous les exemples du cours) :

-   ANOVA √† trois facteurs inter-sujets : <https://www.datanovia.com/en/fr/lessons/anova-dans-r/#three-way-independent-anova>

-   ANOVA √† trois facteurs intra-sujets : <https://www.datanovia.com/en/fr/lessons/anova-sur-mesures-repetees-dans-r/#three-way>

-   ANOVA mixtes √† 3 facteurs : <https://www.datanovia.com/en/fr/lessons/anova-mixte-dans-r/#three-way-bbw-b>

### ANOVA √† 2 facteurs inter-sujets

**L'ANOVA √† 2 facteurs inter-sujets** (*Two-way between-subject ANOVA*) permet de comparer les moyennes issues de plus de deux √©chantillons non-li√©s (i.e., compos√©s d'individus diff√©rents). Il est utilis√© dans le cas o√π vous avez une exp√©rience avec **deux** **VI intergroupes**.

**Jeu de donn√©es utilis√©**

Pour l'exemple, on va prendre le jeu de donn√©es `jobsatisfaction`, qui contient un score de satisfaction au travail de 58 participants, dont 28 hommes et 30 femmes, et selon trois niveaux d'√©tudes (brevet, bac, universit√©).

Ce jeu de donn√©es contient quatre variables :

-   `id` : identifiant du participant

-   `gender` : 1√®re VI - le genre : Homme ou Femme

-   `education_level` : 2nde VI - le niveau d'√©tudes avec 3 niveaux

-   `score` : score de satisfaction au travail.

Les variables `gender` et `education_level` sont toutes deux **des variables intergroupes**, puisque chaque individu n'est concern√© que par une modalit√© de chaque variable. Les individus sont soit des hommes, soit des femmes (variable `gender`) et ont un niveau d'√©tude (variable `education_level`) soit brevet (`school`), soit bac (`college`), soit universitaire (`university`).

On va donc r√©aliser une ANOVA √† 2 facteurs inter-sujets pour √©valuer l'effet du genre et du niveau d'√©tudes sur le score satisfaction au travail.

```{r}
str(jobsatisfaction)
glimpse(jobsatisfaction)
```

#### 1. V√©rification des conditions d'application

<u> Conditions d'application :</u> Elles sont identiques √† celles d'une Anova √† 1 facteur inter-sujet

1.  **Ind√©pendance des observations** : Chaque individu appartient √† un seul groupe. Il n'y a pas de relations entre les observations de chaque groupe. Cette condition revient √† s'assurer que les VI sont bien intergroupes.

2.  **Absence de valeurs aberrantes.** Les donn√©es de chaque groupe ne doivent pas contenir de valeurs aberrantes.

3.  **Normalit√© de la distribution.** Les donn√©es de chaque groupe sont distribu√©es normalement.

4.  **Homog√©n√©it√© des variances.** Les variances de tous les groupes sont homog√®nes.

##### Valeurs aberrantes

On va examiner la pr√©sence de valeurs aberrantes dans les donn√©es de chaque groupe s√©par√©ment.

```{r}
#Boite √† moustaches
ggboxplot(jobsatisfaction, x = "gender", y = "score",
          color = "education_level",
          add = "jitter", bxp.errorbar = TRUE)

#Algorithme
jobsatisfaction %>%
  group_by(gender, education_level) %>%
  identify_outliers(score)

```

**Interpr√©tation :** Aucune valeur aberrante extr√™me n'est d√©tect√©e, on peut poursuivre notre analyse.

##### Normalit√© des distributions

On examine la normalit√© de la distribution dans chaque groupe s√©par√©ment.

```{r, fig.show='hold', fig.asp=1, fig.width=4.5}
#Diagramme QQ
ggqqplot(jobsatisfaction, x = "score", ggtheme = theme_bw()) +
  facet_grid(gender ~ education_level)
```

```{r}
#Tests de Shapiro pour chaque combinaison avec rstatix
jobsatisfaction %>%
  group_by(gender, education_level) %>%
  shapiro_test(score)
```

**Interpr√©tation :** La distribution dans chaque groupe est bien normale (tests de Shapiro, p \> .05), on peut donc continuer avec notre ANOVA.

**Lorsque les donn√©es ne sont pas normales,** on fait comme pour le t-test : soit on garde l'ANOVA parce qu'elle peut r√©sister √† cette non-normalit√©, soit on transforme nos donn√©es. Attention, il n'y a **pas d'alternative non-param√©trique** pour les ANOVA √† 2 facteurs ou plus.

------------------------------------------------------------------------

**L√† encore, on peut examiner la normalit√© de la distribution en analysant les r√©sidus du** **mod√®le** : On utilise le diagramme QQ et le test de Shapiro, non pas sur chaque groupe s√©par√©ment, mais sur les r√©sidus du mod√®le ANOVA.\
Cette approche peut √™tre pratique lorsque vos √©chantillons sont petits.

```{r}
# Cr√©ation du mod√®le lin√©aire
model <- lm(score ~ gender * education_level, data = jobsatisfaction)

# QQ plot
ggqqplot(residuals(model))

#Test de Shapiro
shapiro_test(residuals(model))
```

##### Homog√©n√©it√© des variances

Pour v√©rifier si les variances sont homog√®nes, on va utiliser le **test de Levene**. Comme pour les tests de normalit√©, on estimera que les variances sont homog√®nes lorsque la p-value est sup√©rieure √† .05, puisque son hypoth√®se nulle est que les variances ne sont pas diff√©rentes.

```{r}
# Fonction leveneTest (librairie car)
leveneTest(score ~ gender * education_level, jobsatisfaction)

# Fonction levene_test (librairie rstatix)
levene_test(jobsatisfaction, score ~ gender * education_level)
```

**Interpr√©tation** : La p-value √©tant sup√©rieure √† .05, on peut conclure que les variances sont homog√®nes.

#### 2. Statistiques descriptives et repr√©sentation graphique des donn√©es.

**Statistiques descriptives**

```{r}
  #Librarie rstatix
    #Au global
get_summary_stats(jobsatisfaction, type = "common")

    #En fonction des modalit√©s de chaque variable + Interactino
jobsatisfaction %>%
  group_by(gender) %>%
  get_summary_stats(score)

jobsatisfaction %>%
  group_by(education_level) %>%
  get_summary_stats(score)

jobsatisfaction %>%
  group_by(gender, education_level) %>%
  get_summary_stats(score)
```

**Repr√©sentation graphique**

Quelques exemples de repr√©sentation graphique

```{r, fig.show='hold', fig.asp=1, fig.width= 3}
ggline(jobsatisfaction, plot_type = "b", add = "mean_se", 
       x = "education_level", y = "score", linetype = 2, color = "gender",
       position = position_dodge(width = 0.1),
       xlab = FALSE, ylab = "Score de satisfaction au travail")

ggboxplot(jobsatisfaction, x = "gender", y = "score", add = "jitter", color = "education_level",
          bxp.errorbar = TRUE, xlab = FALSE,
          ylab = "Score de satisfaction au travail")

ggbarplot(jobsatisfaction, x = "gender", y = "score", add = "mean_se", 
          palette = "Set1", fill = "education_level", position = position_dodge(width = 0.8), ylab = "Score de satisfaction au travail")
```

#### 3. R√©alisation de l'ANOVA

Nos conditions d'application √©tant v√©rifi√©es, nous pouvons r√©aliser l'ANOVA √† 2 facteurs. Nous souhaitons savoir si le score diff√®re en fonction du genre ou du niveau d'√©tudes, mais aussi s'il y a un effet d'interaction entre les deux variables.

Comme nous avons deux VI, nous allons devoir examiner les effets principaux de ces deux VI, ainsi que leur effet d'interaction. Pour cela, lorsqu'on utilise la syntaxe sous forme de formule, on utilisera l'ast√©risque `*` pour signifier qu'on souhaite examiner ces trois effets.\
[Syntaxe :]{.underline} `VD ~ VI1 * VI2`

Version avec la fonction `aov()` :

```{r}

#Fonction aov (librairie stats)
res.jb <- aov(score ~ gender * education_level, jobsatisfaction)
summary(res.jb)


```

Version avec la fonction `anova_test()` de la librairie `rstatix` :

```{r}
#Fonction anova_test (librairie rstatix)
  # Version avec la formule
res.jb <- anova_test(jobsatisfaction, score ~ gender * education_level, detailed = TRUE, effect.size = "pes")
get_anova_table(res.jb)

  # Version avec les arguments
res.jb <- anova_test(jobsatisfaction, dv = score, between = c(gender, education_level), detailed = TRUE, effect.size = "pes")
get_anova_table(res.jb)
```

**Interpr√©tation de l'analyse (1) :**

En observant les r√©sultats du test ANOVA, on voit que pour **l'effet principal du niveau d'√©tudes, la p-value est inf√©rieure √† .05, mais pas pour l'effet principal du genre (p = .448)**. On a donc un effet significatif du niveau d'√©tudes uniquement, reste √† savoir si toutes les moyennes sont diff√©rentes entre elles ou non.

On observe ensuite que **l'effet d'interaction** **Genre x Niveau d'√©tudes** est significatif, avec une p-value inf√©rieure √† .05 √† nouveau. On va donc regarder en d√©tail les moyennes dans chaque sous-groupe pour voir quelle est la nature de cet effet d'interaction.

**La taille d'effet pour l'ANOVA nous est donn√©e par l'indicateur eta^2^ partiel**, qui s'interpr√®te de la m√™me mani√®re que l'eta^2^ : l'effet principal du niveau d'√©tudes explique 88% de la variation, et l'effet d'interaction explique 22% de la variation.

[Passons maintenant aux **tests post-hoc** :]{.underline}

Ils consistent √† faire **un ensemble de test-t entre les moyennes de chaque modalit√© deux √† deux**, pour d√©terminer si elles sont significativement diff√©rentes les unes des autres. Comme il y a de multiples tests r√©alis√©s, on applique **une correction de la p-value**. Les tests les plus courants avec l'ANOVA sont les tests de Tukey HSD ou les comparaison avec correction de Bonferroni.

-   Pour **l'effet d'interaction**, on va regarder dans chaque modalit√© d'une VI, les diff√©rences entre les modalit√©s de la 2nde VI.

-   Pour **les effets principaux**, on r√©alise les comparaisons en fonction d'une seule des deux VI.

**Remarque**. On ne r√©alise les comparaisons deux √† deux [uniquement pour les effets significatifs]{.underline}.

```{r}
# Examen de l'effet d'interaction
pwc1.jb <- jobsatisfaction %>%
  group_by(education_level) %>%
  pairwise_t_test(score ~ gender, p.adjust.method = "bonferroni")
pwc1.jb

pwc2.jb <- jobsatisfaction %>%
  group_by(gender) %>%
  pairwise_t_test(score ~ education_level, p.adjust.method = "bonferroni")
pwc2.jb

#Examen de l'effet principal
pwc3.jb <- jobsatisfaction %>%
  pairwise_t_test(score ~ education_level, p.adjust.method = "bonferroni")
pwc3.jb
```

**Remarque.** Dans les tests post-hoc, on examine le d√©tail des effets **statistiquement significatifs seulement**, et on commence par l'effet d'interaction pour redescendre vers les effets principaux.

**Interpr√©tation de l'analyse (2) :**

Les tests post-hoc nous permettent de dire qu'il y bien une diff√©rence en termes de satisfaction de travail entre toutes les modalit√©s du niveau d'√©tudes : globalement, plus le niveau d'√©tudes est √©lev√©, plus la satisfaction est grande (p adj. \< .001).

Pour l'effet d'interaction, on observe qu'il existe une diff√©rence significative entre hommes et femmes [uniquement au niveau "universit√©"]{.underline} (p adj. \< .001).

#### 4. Reporter les r√©sultats

Pour reporter les r√©sultats d'une analyse statistique :

-   On d√©crit les diff√©rences observ√©es et on donne le r√©sultat de l'analyse statistique avec la formule r√©capitulative dans le texte :
    -   Expliquer que l'effet principal du niveau d'√©tudes est significatif : $F(1, 52) = 187.892, p < .001, ùúÇ^2 = 0.88$, ainsi que l'effet d'interaction : $F(2, 52) = 7.338, p < .001, ùúÇ^2 = 0.22$. Cependant, l'effet principal du genre n'est pas significatif : $F(1, 52) = 0.586, p > .400, ùúÇ^2 = 0.01$.

    -   On a une diff√©rence significative au global entre les trois niveaux d'√©tudes (p. adj. \< .001) et la diff√©rence Homme-Femme n'est significative qu'au niveau universit√© (p. adj. \< .001).
-   On peut aussi reporter cette information dans un tableau d√©crivant les donn√©es (par ex : moyenne, √©cart-type, r√©sultat ANOVA + post-hoc).
-   Une repr√©sentation graphique sur laquelle on indique les diff√©rences significatives est aussi appr√©ci√©e .

```{r, fig.show='hold', fig.asp=1, fig.width= 4.5}
# Boxplot + geom_bracket() pour d√©finir manuellement les marques des diff√©rences significatives
ggboxplot(jobsatisfaction, x = "education_level", y = "score",
          bxp.errorbar = TRUE, xlab = FALSE, color = "gender",
          ylab = "score de satisfaction au travail", legend = "none",
          ylim = c(5,12)) +
  geom_bracket(
    xmin = c("school", "college", "school"), xmax = c("college", "university", "university"), y.position = c(8, 10.5, 11.5),
    label = "*", tip.length = c(0.1, 0.02), label.size = 6,
  )

pwc1.jb <- pwc1.jb %>%
  add_xy_position(x = "education_level", dodge = 0.8, fun = "mean_sd")
pwc3.jb <- pwc3.jb %>%
  add_xy_position(x = "education_level", fun = "mean_sd")

ggbarplot(jobsatisfaction, x = "education_level", y = "score", add = "mean_se", 
          palette = "Set1", fill = "gender", position = position_dodge(width = 0.8), ylab = "Score de satisfaction au travail", ylim = c(0, 13)) + 
  stat_pvalue_manual(pwc1.jb, hide.ns = TRUE, tip.length = 0.01) + 
  stat_pvalue_manual(pwc3.jb, hide.ns = TRUE, tip.length = 0.01, step.increase = 0.05)

```

### ANOVA √† 2 facteurs intra-sujets (mesures r√©p√©t√©es)

**L'ANOVA √† 2 facteurs intra-sujets** (*Two-way within-subject ANOVA*) permet de comparer les moyennes issues de plus de deux √©chantillons appari√©s (i.e., compos√©s des m√™mes individus). Il est utilis√© dans le cas o√π vous avez une exp√©rience avec deux **VI intragroupes**.

**Jeu de donn√©es utilis√©**

On va prendre le jeu de donn√©es `selfesteem2`, qui contient le score √† un questionnaire d'estime de soi de 10 individus au cours du temps (trois temps de mesure : T1, T2, T3), qui ont suivi deux phases de test : une 1√®re phase "contr√¥le" sans traitement (avec trois temps de mesure) et une 2nde phase "diet" o√π ils ont suivi un r√©gime (avec trois temps de mesure).

Autrement dit, on mesure le score d'estime de soi des individus aux trois temps de mesure et ces trois temps de mesure sont r√©p√©t√©s pendant les deux phases (soit 2 x 3 mesures r√©p√©t√©es).

```{r}
head(selfesteem2)
```

Ce jeu de donn√©es contient quatre variables :

-   `id` : num√©ro d'identification de l'individu

-   `treatment` : pendant une p√©riode "contr√¥le" (`ctr`), et une p√©riode de r√©gime (`diet`)

-   `t1`, `t2`, `t3` : score au 1er, au 2eme et au 3eme temps de mesure

Les variables `time` (que nous allons cr√©er juste apr√®s) et `treatment` sont toutes deux **des variables intragroupes**, puisque tous les individus passent toutes les modalit√©s de temps (t1, t2, t3), et les deux modalit√©s de la variable `treatment` (d'abord une phase contr√¥le, puis une phase de r√©gime)

On va donc r√©aliser une ANOVA √† 2 facteurs intra-sujets pour √©valuer l'effet du traitement et du temps sur le score d'estime de soi.

```{r}
str(selfesteem2)
glimpse(selfesteem2)
```

**Pr√©paration du jeu de donn√©es**

Comme pour le t-test pour √©chantillons appari√©s, la r√©alisation de l'analyse implique de cr√©er un fichier avec une variable de regroupement et une seule colonne contenant la VD. On utilise √† nouveau la fonction `gather()`.

La colonne `id` est essentielle pour une analyse √† mesures r√©p√©t√©es, afin que le test puisse tenir compte de la variation intra-sujet (au sein d'un m√™me individu). Cette colonne doit √™tre transform√©e en facteur.

```{r}
selfesteem2 <- transform(selfesteem2, id = as.factor(id))

selfesteem2.long <- selfesteem2 %>%
  gather(key = "time", value = "score", t1, t2, t3, factor_key = TRUE)

str(selfesteem2.long)
```

#### 1. V√©rification des conditions d'application

[Conditions d'application :]{.underline} Elles sont identiques √† celles d'une ANOVA √† 2 facteurs intra-sujets

1.  **Appariement des observations** : Chaque individu a une mesure pour chaque modalit√© des VI ; il y a autant de mesures par individu que de modalit√©s dans la variable. Cette condition revient √† s'assurer que les VI sont bien intragroupes.

2.  **Absence de valeurs aberrantes.** Les donn√©es de chaque groupe ne doivent pas contenir de valeurs aberrantes.

3.  **Normalit√© de la distribution.** Les donn√©es de chaque groupe sont distribu√©es normalement.

4.  **Sph√©ricit√© des variances.** L'hypoth√®se de sph√©ricit√© signifie que les variances des diff√©rences entre les conditions sont homog√®nes.

##### Valeurs aberrantes

On examine la pr√©sence de ces valeurs dans les donn√©es de chaque groupe s√©par√©ment.

```{r}
#Boite √† moustaches
ggboxplot(selfesteem2.long, x = "time", y = "score", color = "treatment",
          add = "jitter", bxp.errorbar = TRUE)

#Algorithme
selfesteem2.long %>%
  group_by(time, treatment) %>%
  identify_outliers(score)

```

**Interpr√©tation :** Aucune valeur aberrante extr√™me n'est d√©tect√©e, on peut poursuivre l'analyse.

##### Normalit√© des distributions

On examine la normalit√© de la distribution dans chaque groupe s√©par√©ment.

```{r, fig.show='hold', fig.asp=1, fig.width=4.5}
#Diagramme QQ
ggqqplot(selfesteem2.long, x = "score", ggtheme = theme_bw()) +
  facet_grid(treatment ~ time)
```

```{r}
#test de Shapiro par combinaison de modalit√©s
selfesteem2.long %>%
  group_by(time, treatment) %>%
  shapiro_test(score)
```

**Interpr√©tation :** La distribution dans chaque groupe est bien normale (tests de Shapiro, p \> .05, sauf pour Contr√¥le √† T1, mais sur les diagrammes QQ, l'√©cart n'est pas √©norme), on peut donc continuer avec notre ANOVA.

**Lorsque les donn√©es ne sont pas normales,** on fait comme pour le t-test : soit on garde l'ANOVA parce qu'elle peut r√©sister √† cette non-normalit√©, soit on transforme nos donn√©es. Attention, il n'y a **pas d'alternative non-param√©trique** pour les ANOVA √† 2 facteurs ou plus.

##### Sph√©ricit√©

Pour v√©rifier l'hypoth√®se de sph√©ricit√©, on va utiliser le **test de sph√©ricit√© de Mauchly**. Ce test consiste √† √©valuer si la variance des diff√©rences entre toutes les conditions sont homog√®nes.

En utilisant la fonction `anova_test()` de rstatix, le test de sph√©ricit√© est compris dans la proc√©dure. On verra dans la section de r√©alisation de l'analyse comment obtenir le r√©sultat du test de Mauchly.

**Que faire si la sph√©ricit√© n'est pas respect√©e ?\
**L√† encore, pas de panique, on peut quand m√™me utiliser l'ANOVA, en appliquant des corrections. La plus courante est **la correction de Greenhouse-Geisser (GG)**, qu'on appliquera aux facteurs concern√©s par la violation de la sph√©ricit√©.

En utilisant les fonctions propos√©es par `rstatix`, cette correction sera appliqu√©e en ajoutant l'argument `correction = "auto"` dans la fonction `get_anova_table()`.

#### 2. Statistiques descriptives et repr√©sentation graphique des donn√©es.

**Statistiques descriptives**

```{r}
# Fonction de base pour obtenir des indicateurs statistiques
summary(selfesteem2.long)
summary(selfesteem2)

# Fonctions renvoyant des donn√©es plus compl√®tes
  #Librarie rstatix
    #Au global
get_summary_stats(selfesteem2.long, type = "common")

    #En fonction des modlit√©s de la variable "supp"
selfesteem2.long %>%
  group_by(time, treatment) %>%
  get_summary_stats(score)

```

On observe d'ores et d√©j√† que le score moyen pour le groupe Contr√¥le est de 88 (SD = 8.08) √† T1, de 83.8 (SD = 10.2) √† T2 et de 78.7 (SD = 10.5) √† T3. Pour le groupe Diet, le score moyen est de 87.6 (SD = 7.62) √† T1, de 87.8 (SD = 7.42) √† T2 et de 87.7 (SD = 8.14) √† T3.

**Repr√©sentation graphique**

Quelques exemples de repr√©sentation graphique

```{r, fig.show='hold', fig.asp=1, fig.width= 3}
ggline(selfesteem2.long, plot_type = "b", add = "mean_se", 
       x = "time", y = "score", linetype = 2, color = "treatment",
       position = position_dodge(width = 0.05),
       xlab = FALSE, ylab = "Score d'estime de soi")

ggboxplot(selfesteem2.long, x = "time", y = "score", add = "jitter",
          bxp.errorbar = TRUE, xlab = FALSE, color = "treatment",
          ylab = "Score d'estime de soi", legend = "none")

ggbarplot(selfesteem2.long, x = "treatment", y = "score", add = "mean_se", 
          palette = "Set1", fill = "time", position = position_dodge(width = 0.8), ylab = "Score d'estime de soi",
          legend = "none")
```

#### 3. R√©alisation de l'ANOVA

Nos conditions d'application √©tant v√©rifi√©es, nous pouvons r√©aliser l'ANOVA √† 2 facteurs intra-sujets. Nous souhaitons savoir si le score d'estime de soi est diff√©rent entre T1, T2 et T3, et en fonction du traitement (contr√¥le vs. r√©gime).

Comme pour l'analyse pr√©c√©dente, on va s'int√©resser aux effets principaux des deux VI, ainsi qu'√† l'effet d'interaction.

Version avec la fonction `aov()` - Non recommand√©e

```{r}
#Fonction aov (librairie stats)
res.se2 <- aov(score ~ time * treatment + Error(id/(time*treatment)), selfesteem2.long)
summary(res.se2)
```

Version avec la fonction `anova_test()` de la librairie `rstatix` :

```{r}
#Fonction anova_test (librairie rstatix)
  # Version avec la formule
res.se2 <- anova_test(selfesteem2.long, score ~ time * treatment + Error(id/(time * treatment)), detailed = TRUE)
res.se2
get_anova_table(res.se2, correction = "auto")

  # Version avec les arguments
res.se2 <- anova_test(selfesteem2.long, dv = score, wid = id, within = c(treatment, time), detailed = TRUE)
res.se2
get_anova_table(res.se2, correction = "auto")
```

**Remarque**. Je vous conseille d'utiliser plut√¥t la fonction `anova_test()`, qui est beaucoup plus facile √† utiliser, gr√¢ce √† la possibilit√© d'indiquer vos diff√©rentes variables par des arguments.

**Interpr√©tation de l'analyse (1) :**

En observant les r√©sultats du test ANOVA, on voit que pour **les effets principaux du temps et du traitement, la p-value est inf√©rieure √† .05**. On a donc un effet global significatif des deux VI, reste √† savoir si toutes les moyennes sont diff√©rentes entre elles ou non. **L'effet d'interaction Time x Treatment** est aussi significatif (p \< .05).

On voit aussi que le facteur Temps ne respectait pas l'hypoth√®se de sph√©ricit√©, et a donc √©t√© corrig√© automatiquement dans le rendu de la fonction `get_anova_table()`. La correction de Greenhouse-Geisser consiste √† corriger la valeur des degr√©s de libert√© de ce facteur.

**La taille d'effet pour l'ANOVA nous est donn√©e par l'indicateur eta^2^**, qui s'interpr√®te tr√®s simplement : $eta^2 = 0.06$ signifie que 6% de la variation du score est attribuable au facteur.

[Passons maintenant aux **tests post-hoc** :]{.underline}

Ils consistent √† faire **un ensemble de test-t entre les moyennes de chaque modalit√© deux √† deux**, pour d√©terminer si elles sont significativement diff√©rentes les unes des autres. Comme il y a de multiples tests r√©alis√©s, on applique **une correction de la p-value**.

Ici, il faudra faire attention √† pr√©ciser l'argument `paired = TRUE` pour que les t-tests soit des test appari√©s (mesures r√©p√©t√©es).

```{r}
# Exploration de l'effet d'interaction
pwc1.se2 <- selfesteem2.long %>%
  group_by(treatment) %>%
  pairwise_t_test(score ~ time, paired = TRUE, p.adjust.method = "bonferroni")
pwc1.se2

pwc2.se2 <- selfesteem2.long %>%
  group_by(time) %>%
  pairwise_t_test(score ~ treatment, paired = TRUE, p.adjust.method = "bonferroni")
pwc2.se2

# Exploration de l'effet simple du temps
pwc3.se2 <- selfesteem2.long %>%
  pairwise_t_test(score ~ time, paired = TRUE, p.adjust.method = "bonferroni")
pwc3.se2


```

**Interpr√©tation de l'analyse (2) :**

Les tests post-hoc nous permettent de dire que **les diff√©rences entre T1, T2 et T3 sont significatives (effet principal du temps)**.

Cependant, lorsqu'on explore **l'effet d'interaction significatif**, on s'aper√ßoit que la diff√©rence entre T1, T2 et T3 n'est significative que pour la modalit√© "Contr√¥le", avec une diminution du score au cours du temps. Aussi, on voit que les deux conditions de traitement sont diff√©rentes l'une de l'autre qu'√† T2 et T3.

#### 4. Reporter les r√©sultats

Pour reporter les r√©sultats d'une analyse statistique :

-   On d√©crit les diff√©rences observ√©es et on donne le r√©sultat de l'analyse statistique avec la formule r√©capitulative dans le texte :
    -   Donner les effets significatifs : Pour le traitement :$F(1, 11) = 15.541, p < 0.01, ùúÇ^2 = 0.06$; pour le Temps : $F(1.31, 14.37) = 27.369, p < .001; ùúÇ^2 = 0.05$; pour l'interaction Temps x Traitement : $F(2, 22) = 30.424, p < .001; ùúÇ^2 = 0.05$.

    -   Ici, ce qui va nous int√©resser le plus, c'est de dire que les diff√©rences entre T1, T2 et T3 sont significatives, seulement pour le groupe Contr√¥le (p. adj. \< .01), et que la diff√©rence Contr√¥le vs Diet est significative √† T2 et T3. Cela signifie que la condition "Diet" permet de maintenir le score d'estime soi, alors qu'en contr√¥le, il diminue avec le temps.
-   On peut aussi reporter cette information dans un tableau d√©crivant les donn√©es (par ex : moyenne, ecart-type, r√©sultat ANOVA + post-hoc).
-   Une repr√©sentation graphique sur laquelle on indique les diff√©rences significatives est aussi appr√©ci√©e (ici, ce n'est pas le cas, mais on le verra plus tard).

```{r, fig.show='hold', fig.asp=1, fig.width= 3}

pwc2.se2 <- pwc2.se2 %>% add_xy_position(x = "time", fun = "mean_se")
pwc1.se2 <- pwc1.se2 %>% add_xy_position(x = "time", fun = "mean_se")

ggline(selfesteem2.long, plot_type = "b", add = "mean_se", 
       x = "time", y = "score", linetype = 2, color = "treatment",
       position = position_dodge(width = 0.05),
       xlab = FALSE, ylab = "Score d'estime de soi") +
  stat_pvalue_manual(pwc2.se2, tip.length = 0, hide.ns = TRUE, linetype  = "blank") +
  stat_pvalue_manual(pwc1.se2, color = "treatment", step.group.by = "treatment",
    tip.length = 0.01, step.increase = -0.01, hide.ns = TRUE, bracket.nudge.y = 1) 
```

### ANOVA mixte √† 2 facteurs

**L'ANOVA mixte √† 2 facteurs** (*Two-way mixed ANOVA*) permet de comparer les moyennes avec une VI intergroupe et une VI intra-groupe. On a donc des participants r√©partis dans plusieurs groupes ind√©pendants (VI intergroupe), mais dans lesquels plusieurs mesures sont r√©p√©t√©es (VI intragroupe).

**Jeu de donn√©es utilis√©**

```{r}
head(anxiety)

str(anxiety)
```

Pour cet exemple, on va utiliser le jeu de donn√©es `anxiety`, qui contient les donn√©es de 45 sujets, r√©partis en 3 groupes et pour lesquels on a mesur√© le score d'anxi√©t√© √† trois moments diff√©rents. Les groupes correspondent au niveau d'exercice physique auquel les individus ont particip√©. Ce jeu de donn√©es contient 5 colonnes :

-   `id` : identifiant du participant

-   `group` : groupe d'exercice physique- `grp1` : niveau d√©butant, `grp2` : niveau interm√©diaire, `grp3` : niveau avanc√©

-   `t1`, `t2`, `t3` : score d'anxi√©t√© mesur√© respectivement √† T1, √† T2 et √† T3

La variable `group` est une **variable intergroupe** (chaque participant n'appartient qu'√† un seul groupe) et on va cr√©er la variable `time` (qui contiendra les modalit√©s t1, t2 et t3), qui sera une variable **intra-groupe** (tous les participants passent toutes les modalit√©s - On mesure le score d'anxi√©t√© de tous les participants aux trois temps de mesure).

On va donc r√©aliser une ANOVA mixte √† 2 facteurs pour √©valuer l'effet du niveau d'exercice physique et du temps sur le score d'anxi√©t√©.

**Pr√©paration du jeu de donn√©es**

Comme pour les autres analyses ayant des mesures r√©p√©t√©es, la r√©alisation de l'analyse implique de cr√©er un fichier avec une variable de regroupement et une seule colonne contenant la VD. On utilise √† nouveau la fonction `gather()`.

La colonne `id` est essentielle pour une analyse √† mesures r√©p√©t√©es, afin que le test puisse tenir compte de la variation intra-sujet (au sein d'un m√™me individu). Cette colonne doit √™tre transform√©e en facteur.

```{r}
anxiety <- transform(anxiety, id = as.factor(id))

anxiety.long <- anxiety %>%
  gather(key = "time", value = "score", t1, t2, t3, factor_key = TRUE)

str(anxiety.long)
```

#### 1. V√©rification des conditions d'application

[Conditions d'application :]{.underline} Elles combinent celles de l'ANOVA avec un facteur inter-sujet et de l'ANOVA avec un facteur intra-sujet.

1.  **Absence de valeurs aberrantes.** Les donn√©es de chaque groupe ne doivent pas contenir de valeurs aberrantes.

2.  **Normalit√© de la distribution.** Les donn√©es de chaque groupe sont distribu√©es normalement.

3.  **Homog√©n√©it√© des variances du facteur inter-sujet**. Les variances du facteur inter-sujet doivent √™tre homog√®nes dans chaque modalit√© du facteur intra-sujet

4.  **Sph√©ricit√© des variances du facteur intra-sujet.** L'hypoth√®se de sph√©ricit√© signifie que les variances des diff√©rences entre les conditions sont homog√®nes dans chaque modalit√© du facteur inter-sujet.

##### Valeurs aberrantes

On examine la pr√©sence de ces valeurs dans les donn√©es de chaque groupe s√©par√©ment.

```{r}
#Boite √† moustaches
ggboxplot(anxiety.long, x = "time", y = "score", color = "group",
          add = "jitter", bxp.errorbar = TRUE)

#Algorithme
anxiety.long %>%
  group_by(time, group) %>%
  identify_outliers(score)

```

**Interpr√©tation :** Aucune valeur aberrante extr√™me n'est d√©tect√©e, on peut poursuivre l'analyse.

##### Normalit√© des distributions

On examine la normalit√© de la distribution dans chaque groupe s√©par√©ment.

```{r, fig.show='hold', fig.asp=1, fig.width=4.5}
#Diagramme QQ
ggqqplot(anxiety.long, x = "score", ggtheme = theme_bw()) +
  facet_grid(group ~ time)

#Autre possibilit√©
ggqqplot(anxiety.long, x = "score", facet.by = c("group", "time"))
```

```{r}
#test de Shapiro par combinaison de modalit√©s
anxiety.long %>%
  group_by(time, group) %>%
  shapiro_test(score)
```

**Interpr√©tation :** La distribution dans chaque groupe est bien normale (tests de Shapiro, p \> .05), on peut donc continuer avec notre ANOVA.

**Lorsque les donn√©es ne sont pas normales,** on fait comme pour le t-test : soit on garde l'ANOVA parce qu'elle peut r√©sister √† cette non-normalit√©, soit on transforme nos donn√©es. Attention, il n'y a **pas d'alternative non-param√©trique** pour les ANOVA √† 2 facteurs ou plus.

##### Homog√©n√©it√© des variances

Pour v√©rifier si les variances sont homog√®nes, on va utiliser le **test de Levene**. Comme pour les tests de normalit√©, on estimera que les variances sont homog√®nes lorsque la p-value est sup√©rieure √† .05, puisque son hypoth√®se nulle est que les variances ne sont pas diff√©rentes.

L'homog√©n√©it√© des variances doit √™tre v√©rifi√©e dans chaque modalit√© de la variable intragroupe (`time`)

```{r}
# Fonction levene_test (librairie rstatix)
anxiety.long %>%
  group_by(time) %>%
  levene_test(score ~ group)
```

**Interpr√©tation** : Les p-value √©tant sup√©rieures √† .05, on peut conclure que les variances sont homog√®nes.

##### Sph√©ricit√©

Pour v√©rifier l'hypoth√®se de sph√©ricit√©, on va utiliser le **test de sph√©ricit√© de Mauchly**. Ce test consiste √† √©valuer si la variance des diff√©rences entre toutes les conditions sont homog√®nes.

En utilisant la fonction `anova_test()` de rstatix, le test de sph√©ricit√© est compris dans la proc√©dure. On verra dans la section de r√©alisation de l'analyse comment obtenir le r√©sultat du test de Mauchly.

**Que faire si la sph√©ricit√© n'est pas respect√©e ?\
**L√† encore, pas de panique, on peut quand m√™me utiliser l'ANOVA, en appliquant des corrections. La plus courante est la correction de Greenhouse-Geisser (GG), qu'on appliquera aux facteurs concern√©s par la violation de la sph√©ricit√©.

En utilisant les fonctions propos√©es par `rstatix`, cette correction sera appliqu√©e en ajoutant l'argument `correction = "auto"` dans la fonction `get_anova_table()`.

#### 2. Statistiques descriptives et repr√©sentation graphique des donn√©es.

**Statistiques descriptives**

```{r}
# Fonction de base pour obtenir des indicateurs statistiques
summary(anxiety.long)
summary(anxiety)

# Fonctions renvoyant des donn√©es plus compl√®tes
  #Librarie rstatix
    #Au global
get_summary_stats(anxiety.long, type = "common")

    #En fonction des modlit√©s de la variable "supp"
anxiety.long %>%
  group_by(time, group) %>%
  get_summary_stats(score)

```

**Repr√©sentation graphique**

Quelques exemples de repr√©sentation graphique

```{r, fig.show='hold', fig.asp=1, fig.width= 3}
ggline(anxiety.long, plot_type = "b", add = "mean_se", 
       x = "time", y = "score", linetype = 2, color = "group",
       position = position_dodge(width = 0.05),
       xlab = FALSE, ylab = "Score d'estime de soi")

ggboxplot(anxiety.long, x = "time", y = "score", add = "jitter",
          bxp.errorbar = TRUE, xlab = FALSE, color = "group",
          ylab = "Score d'estime de soi")

ggbarplot(anxiety.long, x = "group", y = "score", add = "mean_se", 
          palette = "Set1", fill = "time", position = position_dodge(width = 0.8), ylab = "Score d'estime de soi")
```

#### 3. R√©alisation de l'ANOVA

Nos conditions d'application √©tant v√©rifi√©es, nous pouvons r√©aliser l'ANOVA mixte √† 2 facteurs. Nous souhaitons savoir si le score d'anxi√©t√© est diff√©rent entre T1, T2 et T3, et en fonction du groupe d'exercice physique.

Comme pour l'analyse pr√©c√©dente, on va s'int√©resser aux effets principaux des deux VI, ainsi qu'√† l'effet d'interaction.

Version avec la fonction `aov()` - Non recommand√©e

```{r}
#Fonction aov (librairie stats)
res.anx <- aov(score ~ group * time + Error(id/time), anxiety.long)
summary(res.anx)
```

Version avec la fonction `anova_test()` de la librairie `rstatix` :

```{r}
#Fonction anova_test (librairie rstatix)
  # Version avec la formule
res.anx <- anova_test(anxiety.long, score ~ group * time + Error(id/time), 
                    effect.size = "pes",detailed = TRUE)
res.anx
get_anova_table(res.anx, correction = "auto")

  # Version avec les arguments
res.anx <- anova_test(anxiety.long, dv = score, wid = id, within = time, between = group, 
                    effect.size = "pes", detailed = TRUE)
res.anx
get_anova_table(res.anx, correction = "auto")
```

**Remarque**. Je vous conseille d'utiliser plut√¥t la fonction `anova_test()`, qui est beaucoup plus facile √† utiliser, gr√¢ce √† la possibilit√© d'indiquer vos diff√©rentes variables par des arguments.

**Interpr√©tation de l'analyse (1) :**

En observant les r√©sultats du test ANOVA, on voit que pour **les effets principaux du temps et du groupe, la p-value est inf√©rieure √† .05**. On a donc un effet global significatif des deux VI, reste √† savoir si toutes les moyennes sont diff√©rentes entre elles ou non. **L'effet d'interaction Time x Group** est aussi significatif (p \< .05)

**La taille d'effet pour l'ANOVA nous est donn√©e par l'indicateur eta^2^ partiel**, qui s'interpr√®te tr√®s simplement : $eta^2 = 0.17$ signifie que 17% de la variation du score est attribuable aux conditions de traitement.

[Passons maintenant aux **tests post-hoc** :]{.underline}

Ils consistent √† faire **un ensemble de test-t entre les moyennes de chaque modalit√© deux √† deux**, pour d√©terminer si elles sont significativement diff√©rentes les unes des autres. Comme il y a de multiples tests r√©alis√©s, on applique **une correction de la p-value** (ici, on utilise des "*pairwise t-tests*" avec correction de Bonferroni).

```{r}
# Exploration de l'effet d'interaction
pwc1.anx <- anxiety.long %>%
  group_by(group) %>%
  pairwise_t_test(score ~ time, paired = TRUE, p.adjust.method = "bonferroni")
pwc1.anx

pwc2.anx <- anxiety.long %>%
  group_by(time) %>%
  pairwise_t_test(score ~ group, p.adjust.method = "bonferroni")
pwc2.anx

# Exploration de l'effet simple du temps
pwc3.anx <- anxiety.long %>%
  pairwise_t_test(score ~ time, paired = TRUE, p.adjust.method = "bonferroni")
pwc3.anx

# Exploration de l'effet simple du groupe
pwc4.anx <- anxiety.long %>%
  pairwise_t_test(score ~ group, p.adjust.method = "bonferroni")
pwc4.anx


```

**Interpr√©tation de l'analyse (2) :**

**Sur les effets principaux,** on voit que globalement, le score d'anxi√©t√© est diff√©rent entre toutes les modalit√©s de la variable Temps (T1 \> T2 \> T3). On voit aussi que pour l'effet principal du groupe, le score d'anxi√©t√© est diff√©rent entre le groupe 1 et le groupe 3, ainsi qu'entre le groupe 2 et le groupe 3. Par contre, il n'y a pas de diff√©rence significative entre groupe 1 et groupe 2.

**En ce qui concerne l'effet d'interaction**, on observe que :

-   La diff√©rence entre T1 et T2 n'est pas significative pour les groupes 1 et 2, mais elle est significative pour le groupe 3. Cela signifie que le score d'anxi√©t√© diminue plus t√¥t dans le groupe 3 par rapport aux autres

-   √Ä T1, les scores de chaque groupe ne sont pas diff√©rents entre eux. √Ä T2, le groupe 3 a un score significativement diff√©rent du groupe 1 seulement, et √† T3, le groupe 3 a un score significativement diff√©rent des deux autres groupes.

Ces √©l√©ment r√©unis nous permettent de dire que de l'exercice physique intense (niveau avanc√©) permet de r√©duire plus vite et plus efficacement le score d'anxi√©t√©, par rapport √† de l'exercice physique moins intense (niveaux interm√©diaire et avanc√©)

#### 4. Reporter les r√©sultats

Pour reporter les r√©sultats d'une analyse statistique :

-   On d√©crit les diff√©rences observ√©es et on donne le r√©sultat de l'analyse statistique avec la formule r√©capitulative dans le texte :
    -   Donner les effets significatifs :\
        Pour le groupe :$F(2, 42) = 4.352, p < 0.05, ùúÇ^2 = 0.17$;\
        Pour le Temps : $F(2, 84) = 394.909, p < .05; ùúÇ^2 = 0.90$;\
        Pour l'interaction Temps x Groupe : $F(4, 84) = 110.188, p < .05; ùúÇ^2 = 0.84$

    -   On d√©crit les diff√©rences observ√©es dans les tests post-hoc, en pr√©cisant la p-value ajust√©e associ√©e aux diff√©rences notables.
-   On peut aussi reporter cette information dans un tableau d√©crivant les donn√©es (par ex : moyenne, √©cart-type, r√©sultat ANOVA + post-hoc).
-   Une repr√©sentation graphique sur laquelle on indique les diff√©rences significatives est aussi appr√©ci√©e (ici, ce n'est pas le cas, mais on le verra plus tard).

```{r}
pwc2.anx <- pwc2.anx %>% add_xy_position(x = "time")

ggboxplot(anxiety.long, x = "time", y = "score", 
          bxp.errorbar = TRUE, xlab = FALSE, color = "group",
          ylab = "Score d'estime de soi") + 
  stat_pvalue_manual(pwc2.anx, tip.length = 0.02, hide.ns = TRUE)
```

# Comparaison de moyennes avec ajout d'une covariable

Les **covariables** sont des variables parasites que vous avez mesur√© afin de pouvoir tenir compte de leur influence sur le mod√®le que vous souhaitez tester. Autrement dit, lorsque vous r√©alisez votre comparaison de moyennes pour √©valuer l'impact d'une ou plusieurs VI sur la VD, vous souhaitez "retirer" l'influence de cette covariable sur les r√©sultats.

**L'ANCOVA** est un type d'ANOVA qui permet de "supprimer" l'influence d'une covariable avant de r√©aliser l'ANOVA avec les facteurs d'int√©r√™t.

Par exemple, si vous faites une exp√©rience dans laquelle vous mesurez l'impact d'un serious game sur l'apprentissage des math√©matiques, il peut √™tre pertinent de contr√¥ler le niveau initial de math√©matiques des enfants, afin d'examiner uniquement l'impact du serious game (quel que soit le niveau de math√©matiques initial des enfants).

Cette proc√©dure est souvent utilis√©e lorsqu'on r√©alise des exp√©riences avec un protocole pr√©-post (c'est-√†-dire qu'on mesure la VD avant et apr√®s une intervention). Dans ce cas, il est d'usage de mettre en covariable le score au pr√©-test, et d'√©valuer l'impact de l'intervention sur le score post-test (entre un groupe contr√¥le et un groupe √©quip√©).

## Conditions d'application d'une ANCOVA

L'ANCOVA a plusieurs conditions d'application suppl√©mentaires par rapport √† une ANOVA classique :

1.  **Absence de valeurs aberrantes.**
2.  **Normalit√© des distributions.**
3.  **Homosc√©dasticit√©.** Cela correspond √† l'homog√©n√©it√© des variances des r√©sidus du mod√®le.
4.  **Lin√©arit√© entre la VD et la covariable.**
5.  **Homog√©n√©it√© des pentes de r√©gression.** Les pentes des droites de r√©gression, form√©es par la covariable et la VD, devraient √™tre les m√™mes pour chaque groupe. Cette hypoth√®se √©value qu'il n'y a pas d'interaction entre le r√©sultat et la covariable.

## ANCOVA √† 1 facteur

**Jeu de donn√©es utilis√©**

On va r√©utiliser le jeu de donn√©es `anxiety` pour illustrer cette analyse, en conservant que les scores T1 et T3. La situation exp√©rimentale aurait pour objectif d'√©valuer un programme d'exercice physique sur le score d'anxi√©t√©, mesur√© avant et apr√®s que les individus aient particip√© au programme.

Dans ce cas, on peut se demander si le score initial d'anxi√©t√© des individus pourrait avoir impact√© l'efficacit√© des programmes d'exercice physique sur l'√©volution de l'anxi√©t√©. On va donc contr√¥ler l'impact du niveau initial d'anxi√©t√©, avant d'examiner l'effet du programme sur le score d'anxi√©t√© final.

On utilisera donc le score pr√©-test comme covariable et examinerons les diff√©rence sur le score post-test (VD) en fonction du groupe (VI).

```{r}
# Retrait de la colonne T2 + Renommer les colonnes T1 et T3
anxiety2 <- anxiety %>%
  select(id, group, t1, t3) %>%
  rename(pretest = t1, posttest = t3)

# On modifie la valeur du participant 14 pour que l'exemple soit parlant sur les conditions d'application
anxiety2[14, "posttest"] <- 19
```

### 1. V√©rification des conditions d'application

#### Valeurs aberrantes

Comme pour les ANOVA, on v√©rifie la pr√©sence de valeurs aberrantes dans chaque sous-groupe.

```{r, fig.show='hold', fig.asp=1, fig.width= 4.5}
anxiety2 %>%
  group_by(group) %>%
  identify_outliers(posttest)

anxiety2 %>%
  group_by(group) %>%
  identify_outliers(pretest)


ggboxplot(anxiety2, x = "group", y = "posttest", add = "jitter",
          bxp.errorbar = TRUE, xlab = FALSE, color = "group")

ggboxplot(anxiety2, x = "group", y = "pretest", add = "jitter",
          bxp.errorbar = TRUE, xlab = FALSE, color = "group")

```

**Interpr√©tation** : Il n'y a aucune valeur aberrante dans le jeu de donn√©es, que ce soit sur la VD ou la covariable.

#### Normalit√© des distributions

Comme pour les ANOVA, on v√©rifie la normalit√© dans chaque sous-groupe.

```{r, fig.show='hold', fig.asp=1, fig.width= 4.5}
ggqqplot(anxiety2, x = "posttest", facet.by = "group")
ggqqplot(anxiety2, x = "pretest", facet.by = "group")

anxiety2 %>%
  group_by(group) %>%
  shapiro_test(pretest, posttest)

```

**Interpr√©tation** : La VD et la covariable sont normalement distribu√©es (Shapiro, p \< .05).

------------------------------------------------------------------------

Comme il s'agit d'une ANOVA avec 1 facteur inter-sujet, on peut aussi v√©rifier la normalit√© de la distribution de la VD en utilisant les r√©sidus du mod√®le (incluant la covariable). Cette technique est d'autant mieux car la normalit√© sera v√©rifi√©e en tenant compte de la covariable.

```{r}
# Construction du mod√®le - La covariable vient toujours en premier, et on ajoute la VI avec le signe + (et non le signe *)

model <- lm(posttest ~ pretest + group, data = anxiety2)

ggqqplot(residuals(model))

shapiro_test(residuals(model))
```

#### Homosc√©dasticit√©

Contrairement aux ANOVA classiques dans lesquelles on v√©rifie l'homog√©n√©it√© des variances sur la VD, l'hypoth√®se d'homosc√©dasticit√© suppose que les variances des r√©sidus dans chaque groupe sont homog√®nes.

Comme on doit v√©rifier l'homosc√©dasticit√© en fonction du groupe, on va d'abord ajouter les r√©sidus √† notre jeu de donn√©es, puis r√©aliser le test de Levene.

```{r}
# Ajout d'une colonne contenant les r√©sidus du mod√®le
anxiety2 <- cbind(anxiety2, resid = residuals(model))

anxiety2 %>% 
  levene_test(resid ~ group)
```

**Interpr√©tation :** Le test de Levene renvoie une p-value sup√©rieure √† .05, donc l'homosc√©dasticit√© est respect√©e.

#### Lin√©arit√© de la covariable et de la VD

Nous devons v√©rifier que pour chaque condition de la VI, la VD et la covariable ont une relation lin√©aire entre elles.

```{r}
# M√©thode 1 : Calcul des coefficients de corr√©lation entre la VD et la covariable dans chaque groupe
anxiety2 %>%
  group_by(group) %>%
  cor_test(posttest, pretest)

```

```{r, fig.show='hold', fig.asp=1, fig.width= 4.5}
# M√©thode 2 : Faire un graphique en nuage de points (scatterplot), et tracer les droites de r√©gression
ggscatter(anxiety2, x = "pretest", y = "posttest",
  color = "group", add = "reg.line")

# On peut ajouter √† ce graphe l'√©quation des droites et le R2 (qui quantifie la force de la relation)
ggscatter(anxiety2, x = "pretest", y = "posttest",
  color = "group", add = "reg.line")+
  stat_regline_equation(
    aes(label =  paste(..rr.label..), color = group)
    )
```

#### Homog√©n√©it√© des pentes de r√©gression

Cette condition revient √† v√©rifier qu'il n'y a pas d'interaction entre la covariable et la VI. Autrement dit, on doit avoir une relation similaire entre la VD et la covariable, √† tous les niveaux de la VI.

Cela revient √† examiner s'il existe un effet d'interaction entre la covariable et la VI.

```{r}
# Homog√©n√©it√© des pentes : ANOVA(VD ~ VI * COV)
anova_test(anxiety2, posttest ~ group * pretest)
```

**Interpr√©tation** : Comme il n'y a pas d'effet d'interaction entre le VI et la covariable, on peut confirmer que les pentes de r√©gression sont homog√®nes. La condition est donc v√©rifi√©e.

**Remarque.** On peut examiner cette condition sur le graphe pr√©c√©dent (voir ci-dessous). En effet, le fait que les trois droites soient parall√®les montre qu'il n'y a pas d'effet d'interaction entre la covariable et la VI.

```{r}
ggscatter(anxiety2, x = "pretest", y = "posttest",
  color = "group", add = "reg.line")
```

### 2. R√©alisation de l'ANCOVA

On va utiliser la fonction `anova_test()` qui est plus facile √† utiliser pour r√©aliser une ANCOVA.

**Si vous utilisez la version avec la formule,** il faudra √™tre bien vigilant √† mettre la covariable en 1er dans la liste des VI et la s√©parer d'un signe `+` et non d'un signe `*`.\
[Syntaxe :]{.underline} `VD ~ COV + VI`

```{r}

# Version avec la formule
res.anx2 <- anova_test(anxiety2, posttest ~ pretest + group)
res.anx2

# Version avec les argument
res.anx2 <- anova_test(anxiety2, dv = posttest, covariate = pretest, between = group)
res.anx2
```

**Interpr√©tation** : Apr√®s avoir contr√¥l√© l'impact de la covariable sur le score pr√©-test, on peut conclure qu'il y a un effet significatif du groupe sur le score.

[Passons maintenant aux **tests post-hoc** :]{.underline}

Pour les tests post-hoc, on va utiliser la fonction `emmeans_test()` qui permet de r√©aliser les comparaisons deux √† deux sur des **moyennes marginales corrig√©es** (c'est-√†-dire des moyennes ajust√©es en tenant compte de l'impact de la covariable).

```{r}
# Comparaisons 2 √† 2 avec covariable
pwc.anx2 <- anxiety2 %>% 
  emmeans_test(
    posttest ~ group, covariate = pretest)
pwc.anx2
```

**Interpr√©tation** : Les comparaisons deux √† deux nous permettent de conclure, qu'apr√®s contr√¥le de la covariable, les diff√©rences sont significatives entre toutes les modalit√©s de la variable groupe.

Pour obtenir la valeur des moyennes corrig√©es, on peut utiliser la fonction `get_emmeans()`.

```{r}
get_emmeans(pwc.anx2)
```

### 3. Reporter les r√©sultats

Pour reporter les r√©sultats d'une ANCOVA :

-   On d√©crit les diff√©rences observ√©es et on donne le r√©sultat de l'analyse statistique avec la formule r√©capitulative dans le texte :
    -   Apr√®s ajustement des scores post-test par la covariable (score pr√©-test), on peut conclure qu'il y a un effet significatif du groupe : $F(2, 41) = 218.629, p < 0.001, ùúÇ^2 = 0.91$.

    -   On d√©crit les diff√©rences observ√©es dans les tests post-hoc, en pr√©cisant la p-value ajust√©e associ√©e aux diff√©rences notables. Ici, on a observ√© que les moyennes ajust√©es sont significativement diff√©rentes les unes des autres (p. adj. \< .001). Le score d'anxi√©t√© post-test est plus faible dans le groupe 3 par rapport aux groupes 1 et 2, et ce m√™me score est plus faible dans le groupe 2 par rapport au groupe 1.
-   On peut aussi reporter cette information dans un tableau d√©crivant les donn√©es (par ex : moyenne, √©cart-type, r√©sultat ANOVA + post-hoc).
-   Une repr√©sentation graphique sur laquelle on indique les diff√©rences significatives est aussi appr√©ci√©e.

```{r}
#Graphe repr√©sentant les moyennes ajust√©es par la covariable
pwc.anx2 <- pwc.anx2 %>% add_xy_position(x = "group", fun = "mean_se")
ggline(get_emmeans(pwc.anx2), x = "group", y = "emmean") +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high), width = 0.1) + 
  stat_pvalue_manual(pwc.anx2, hide.ns = TRUE, tip.length = 0.01, 
                     bracket.nudge.y = -0.5, step.increase = -0.05)


```

## ANCOVA √† 2 facteurs

**Jeu de donn√©es utilis√©**

On va utiliser le jeu de donn√©es `stress` pour illustrer cette analyse. Ce jeu de donn√©es se compose des score de 60 participants r√©parties selon deux variables inter-groupes, et pour lesquels on a mesur√© le stress.

Dans ce jeu de donn√©es, nous allons analyser l'impact des deux VI (`treatment` et `exercise`) sur ce score de stress, en contr√¥lant l'impact de la variable `age`. Autrement dit, la question est de savoir, en tenant compte de l'√¢ge des participants, quel est l'impact du traitement et de l'exercice physique sur le stress.

```{r}
str(stress)
glimpse(stress)
```

Ce jeu de donn√©es contient 5 colonnes :

-   `id` : identifiant du participant

-   `score` : mesure du stress

-   `treatment` : traitement √† deux modalit√©s - avec vs. sans traitement

-   `exercise` : intensit√© du programme d'exercice physique - faible vs. mod√©r√© vs. √©lev√©

-   `age` : √¢ge des participants

### 1. V√©rification des conditions d'application

#### Valeurs aberrantes

Comme pour les ANOVA, on v√©rifie la pr√©sence de valeurs aberrantes dans chaque sous-groupe.

```{r, fig.show='hold', fig.asp=1, fig.width= 4.5}
stress %>%
  group_by(treatment, exercise) %>%
  identify_outliers(score)

stress %>%
  group_by(treatment, exercise) %>%
  identify_outliers(age)


ggboxplot(stress, x = "treatment", y = "score", add = "jitter",
          bxp.errorbar = TRUE, xlab = FALSE, color = "exercise")

ggboxplot(stress, x = "treatment", y = "age", add = "jitter",
          bxp.errorbar = TRUE, xlab = FALSE, color = "exercise")

```

**Interpr√©tation** : Une valeur est identifi√©e comme √©tant extr√™me, mais on va la conserver.

#### Normalit√© des distributions

Comme pour les ANOVA, on v√©rifie la normalit√© dans chaque sous-groupe.

```{r, fig.show='hold', fig.asp=1, fig.width= 4.5}
ggqqplot(stress, x = "score", facet.by = c("treatment", "exercise"))
ggqqplot(stress, x = "age", facet.by = c("treatment", "exercise"))

stress %>%
  group_by(exercise, treatment) %>%
  shapiro_test(score, age)

```

**Interpr√©tation** : La VD et la covariable sont normalement distribu√©es (Shapiro, p \< .05).

------------------------------------------------------------------------

Comme il s'agit d'une ANOVA avec 2 facteurs inter-sujets, on peut v√©rifier la normalit√© de la distribution de la VD en utilisant les r√©sidus du mod√®le (incluant la covariable). Cette technique est d'autant mieux car la normalit√© sera v√©rifi√©e en tenant compte de la covariable.

```{r}
# Construction du mod√®le - La covariable vient toujours en premier, et on ajoute la VI avec le signe + (et non le signe *)

model <- lm(score ~ age + treatment * exercise, data = stress)

ggqqplot(residuals(model))

shapiro_test(residuals(model))
```

#### Homosc√©dasticit√©

Contrairement aux ANOVA classiques dans lesquelles on v√©rifie l'homog√©n√©it√© des variances sur la VD, l'hypoth√®se d'homosc√©dasticit√© suppose que les variances des r√©sidus dans chaque groupe sont homog√®nes.

Comme on doit v√©rifier l'homosc√©dasticit√© en fonction du groupe, on va d'abord ajouter les r√©sidus √† notre jeu de donn√©es, puis r√©aliser le test de Levene.

```{r}
# Ajout d'une colonne contenant les r√©sidus du mod√®le
stress <- cbind(stress, resid = residuals(model))

stress %>% 
  levene_test(resid ~ exercise * treatment)
```

**Interpr√©tation :** Le test de Levene renvoie une p-value sup√©rieure √† .05, donc l'homosc√©dasticit√© est respect√©e.

#### Lin√©arit√© de la covariable et de la VD

Nous devons v√©rifier que pour chaque condition de la VI, la VD et la covariable ont une relation lin√©aire entre elles.

```{r}
# M√©thode 1 : Calcul des coefficients de corr√©lation entre la VD et la covariable dans chaque groupe
stress %>%
  group_by(exercise, treatment) %>%
  cor_test(score, age)

```

```{r, fig.show='hold', fig.asp=1, fig.width= 4.5}
# M√©thode 2 : Faire un graphique en nuage de points (scatterplot), et tracer les droites de r√©gression
ggscatter(stress, x = "age", y = "score",
  facet.by  = c("exercise", "treatment"), add = "reg.line")+
  stat_smooth(method = "loess", span = 0.9)
```

#### Homog√©n√©it√© des pentes de r√©gression

Cette condition revient √† v√©rifier qu'il n'y a pas d'interaction entre la covariable et la VI. Autrement dit, on doit avoir une relation similaire entre la VD et la covariable, √† tous les niveaux de la VI.

Cela revient √† examiner s'il existe un effet d'interaction entre la covariable et la VI.

```{r}
# Homog√©n√©it√© des pentes : ANOVA(VD ~ VI * COV)
anova_test(stress, score ~ treatment * exercise * age)
```

**Interpr√©tation** : Comme il n'y a pas d'effet d'interaction entre les VI et la covariable, on peut confirmer que les pentes de r√©gression sont homog√®nes. La condition est donc v√©rifi√©e.

### 2. R√©alisation de l'ANCOVA

On va utiliser la fonction `anova_test()` qui est plus facile √† utiliser pour r√©aliser une ANCOVA.

**Si vous utilisez la version avec la formule,** il faudra √™tre bien vigilant √† mettre la covariable en 1er dans la liste des VI et la s√©parer d'un signe `+` et non d'un signe `*`.\
[Syntaxe :]{.underline} `VD ~ COV + VI * VI`.

```{r}

# Version avec la formule
res.str <- anova_test(stress, score ~ age + treatment * exercise)
res.str

# Version avec les argument
res.str <- anova_test(stress, dv = "score", covariate = "age", between = c("treatment", "exercise"))
res.str
```

**Interpr√©tation** : Apr√®s avoir contr√¥l√© l'impact de la covariable sur le score pr√©-test, on peut conclure qu'il y a un effet significatif du traitement et un effet significatif de l'exercice physique, ainsi qu'un effet d'interaction Traitement x Exercice.

[Passons maintenant aux **tests post-hoc** :]{.underline}

Pour les tests post-hoc, on va utiliser la fonction `emmeans_test()` qui permet de r√©aliser les comparaisons deux √† deux sur des **moyennes marginales corrig√©es** (c'est-√†-dire des moyennes ajust√©es en tenant compte de l'impact de la covariable).

```{r}
# Effet d'interaction : Comparaisons 2 √† 2 avec covariable
pwc1.str <- stress %>% 
  group_by(treatment) %>%
  emmeans_test(
    score ~ exercise, covariate = age)
pwc1.str

pwc2.str <- stress %>% 
  group_by(exercise) %>%
  emmeans_test(
    score ~ treatment, covariate = age)
pwc2.str

# Effet principal de l'exercice physique
pwc3.str <- stress %>% 
  emmeans_test(
    score ~ exercise, covariate = age)
pwc3.str

# Effet principal du traitement (permet juste d'obtenir les moyennes ajust√©es)
pwc4.str <- stress %>% 
  emmeans_test(
    score ~ exercise, covariate = age)
pwc4.str
```

**Interpr√©tation** : Les comparaisons deux √† deux nous permettent de conclure, qu'apr√®s contr√¥le de la covariable, les diff√©rences sont significatives entre le groupe `high` et les groupes `low` et `moderate`, seulement lorsqu'ils ont le traitement (`yes`). Aussi, la diff√©rence entre avec et sans traitement est significative uniquement dans la modalit√© d'exercice physique √©lev√©e (`high`)

Pour obtenir la valeur des moyennes corrig√©es, on peut utiliser la fonction `get_emmeans()`.

```{r}
get_emmeans(pwc1.str)
get_emmeans(pwc2.str)
get_emmeans(pwc3.str)
get_emmeans(pwc4.str)
```

### 3. Reporter les r√©sultats

Pour reporter les r√©sultats d'une ANCOVA :

-   On d√©crit les diff√©rences observ√©es et on donne le r√©sultat de l'analyse statistique avec la formule r√©capitulative dans le texte :
    -   Apr√®s avoir contr√¥l√© l'influence de l'√¢ge sur les scores de stress ($F(1, 53) = 9.110, p < 0.01, ùúÇ^2 = 0.15$), on peut conclure qu'il y a :\
        Effet principal du Traitement : $F(1, 53) = 11.096, p < 0.01, ùúÇ^2 = 0.17$,\
        Effet principal de l'Exercice : $F(2, 53) = 20.820, p < 0.001, ùúÇ^2 = 0.44$,\
        Effet d'interaction : $F(2, 53) = 4.446, p < 0.05, ùúÇ^2 = 0.14$.

    -   On d√©crit les diff√©rences observ√©es dans les tests post-hoc, en pr√©cisant la p-value ajust√©e associ√©e aux diff√©rences notables. Ici, on a observ√© que le score moyen ajust√© par l'√¢ge diminue significativement avec le traitement que lorsqu'il s'accompagne d'une activit√© physique intense (par rapport √† une activit√© faible √† mod√©r√©e).
-   On peut aussi reporter cette information dans un tableau d√©crivant les donn√©es (par ex : moyenne, √©cart-type, r√©sultat ANOVA + post-hoc).
-   Une repr√©sentation graphique sur laquelle on indique les diff√©rences significatives est aussi appr√©ci√©e.

```{r}
#Graphe repr√©sentant les moyennes ajust√©es par la covariable
pwc2.str <- pwc2.str %>% add_xy_position(x = "exercise", fun = "mean_se")
pwc1.str <- pwc1.str %>% add_xy_position(x = "exercise", fun = "mean_se")
ggline(get_emmeans(pwc2.str), x = "exercise", y = "emmean", color = "treatment") +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high, color = treatment), width = 0.1) + 
  stat_pvalue_manual(
  pwc2.str, hide.ns = TRUE, tip.length = 0, bracket.size = 0, bracket.nudge.y = -6) + 
  stat_pvalue_manual( pwc1.str, hide.ns = TRUE, tip.length = 0.05, 
                      step.group.by = "treatment", color = "treatment")
```

# Comparaison de moyennes avec plusieurs variables d√©pendantes

**L'Analyse Multivari√©e de la variance (MANOVA)** est un type d'ANOVA qui est utilis√©e dans le cas o√π on a plusieurs VD √† examiner (les VD doivent mesurer diff√©rents aspects du ph√©nom√®ne √† √©tudier).\
En effet, le fait de r√©p√©ter plusieurs tests augmente le risque d'erreur (car on r√©alise plusieurs tests sur les m√™mes donn√©es). De plus, la MANOVA permet de prendre en compte de la covariation des diff√©rentes VD.

**Jeu de donn√©es utilis√©**

Pour cet exemple, on va utiliser le jeu de donn√©es `iris`, qui contient 150 observations de trois esp√®ces d'iris, et se compose de 5 colonnes :

-   `Sepal.Length` : Longueur des s√©pales

-   `Sepal.Width` : Largeur des s√©pales

-   `Petal.Length` : Longueur des p√©tales

-   `Petal.Width` : Largeur des p√©tales

-   `Species` : Esp√®ce d'iris (setosa, virginica, versicolor)

```{r}
iris2 <- cbind(id = 1:nrow(iris), iris)
head(iris2)
```

Pour l'exemple, on va s'int√©resser aux variables `Sepal.Length` et `Petal.Length` en fonction du groupe `Species`.

## 1. V√©rification des conditions d'application

La MANOVA a un certain nombre de conditions d'application :

1.  **Ind√©pendance des observations :** Les MANOVA ne concernent pas les mesures r√©p√©t√©es. Chaque individu n'est affect√© qu'√† une modalit√© de la VI test√©e
2.  **Absence de valeurs aberrantes univari√©es et multivari√©es**
3.  **Normalit√© univari√©e et multivari√©e des distributions**
4.  **Multicollin√©arit√© et Lin√©arit√©** : Il doit exister une relation lin√©aire entre les variables d√©pendantes, qui ne doit pas √™tre ni trop forte, ni trop faible.
5.  **Homog√©n√©it√© des variances**
6.  **Homog√©n√©it√© des matrices de variance-covariance**

### Valeurs aberrantes univari√©es et multivari√©es

On va v√©rifier l'absence de valeurs aberrantes pour chaque VD (**univari√©es**), en fonction du groupe. Pour cela, on utilise la m√™me proc√©dure que pour une ANOVA classique :

```{r}
# Boite √† moustache
ggboxplot(
  iris2, x = "Species", y = c("Sepal.Length", "Petal.Length"), 
  merge = TRUE, palette = "jco"
  )

#Identify_outliers()
iris2 %>%
  group_by(Species) %>%
  identify_outliers(Sepal.Length)

iris2 %>%
  group_by(Species) %>%
  identify_outliers(Petal.Length)
```

**Interpr√©tation** : Pas de valeurs aberrantes extr√™mes, on peut poursuivre.

On va aussi v√©rifier la pr√©sence de valeurs aberrantes **multivari√©es**, qui sont des points dont les valeurs sur les deux VD ont une combinaison aberrante. Autrement dit, les valeurs pour chaque VD d'un individu sont trop √©loign√©es ou trop proches par rapport au reste de l'√©chantillon.

Pour cela, on utilise un indicateur de la distance entre une observation et le reste de l'√©chantillon, en l'occurrence, la **distance de Mahalanobis**, qui traduit donc l'√©loignement d'une observation par rapport √† la tendance du reste de l'√©chantillon

```{r}
# Aper√ßu du rendu de la fonction
iris2 %>%
  select(Species, Sepal.Length, Petal.Length) %>%
  group_by(Species) %>%
  mahalanobis_distance() %>%
  head()
  
iris2 %>%
  select(Species, Sepal.Length, Petal.Length) %>%
  group_by(Species) %>%
  mahalanobis_distance() %>% 
  filter(is.outlier == TRUE) %>%
  as.data.frame()
```

### Normalit√© univari√©e et multivari√©e

Pour la normalit√© univari√©e, on utilise la proc√©dure classique avec le test de Shapiro, et pour la normalit√© multivari√©e, on utilise une variante de cette fonction : `mshapiro()`

```{r}
#Normalit√© univari√©e
iris2 %>%
  group_by(Species) %>%
  shapiro_test(Sepal.Length, Petal.Length) %>%
  arrange(variable)

ggqqplot(iris2, "Sepal.Length", facet.by = "Species",
         ylab = "Sepal Length", ggtheme = theme_bw())
ggqqplot(iris2, "Petal.Length", facet.by = "Species",
         ylab = "Petal Length", ggtheme = theme_bw())

#Normalit√© multivari√©e
iris2 %>%
  select(Sepal.Length, Petal.Length) %>%
  mshapiro_test()
```

### Multicollin√©arit√© et lin√©arit√© entre les VD

Au global, on va contr√¥ler la corr√©lation entre les deux VD pour v√©rifier si elles ne sont pas trop corr√©l√©es (r \< .90). Sinon, il y aura multicollin√©arit√© : dans ce cas, il faudra envisager de supprimer une des deux VD.

Si la corr√©lation est trop faible, la MANOVA n'est plus justifi√©e (pas assez de lien entre les VD), et il faudra faire deux ANOVA s√©par√©es.

On calcule le coefficient de corr√©lation de Pearson pour d√©terminer la corr√©lation entre les deux VD. Ici, on obtient une corr√©lation de .87, ce qui est bon pour faire une MANOVA.

```{r}
iris2 %>% cor_test(Sepal.Length, Petal.Length)
```

Pour v√©rifier la **lin√©arit√©**, il faut qu'il y ait une relation lin√©aire entr les deux VD pour chaque modalit√© de la VI (donc, en fonction du groupe). On peut utiliser la fonction `ggpairs()` pour visualiser graphiquement la relation entre les deux VD par groupe, ou tout simplement faire un `cor_test()` en fonction du groupe.

```{r}
results <- iris2 %>%
  select(Sepal.Length, Petal.Length, Species) %>%
  group_by(Species) %>%
  doo(~ggpairs(.) + theme_bw(), result = "plots")
results$plots

iris2 %>% 
  group_by(Species) %>%
  cor_test(Sepal.Length, Petal.Length)
```

### Homog√©n√©it√© des variances 

On utilise le test de Levene pour tester l'homog√©n√©it√© des variances

```{r}
iris2 %>%
  levene_test(Petal.Length ~ Species)
iris2 %>%
  levene_test(Sepal.Length ~ Species)
```

**Interpr√©tation** : Ici, nous n'avons pas d'homog√©n√©it√© des variances. Il faudra √™tre vigilant sur la MANOVA et quoi qu'il en soit faire une ANOVA de Welch en post-hoc pour compenser ce probl√®me.

### Homog√©n√©it√© des matrices de variance-covariance

Pour tester cette hypoth√®se, on utilise le test de Box-M : l'hypoth√®se est respect√©e lorsque la p-value est sup√©rieure √† .05

```{r}
box_m(iris2[, c("Sepal.Length", "Petal.Length")], iris2$Species)
```

**Interpr√©tation** : Ici, nous n'avons pas d'homog√©n√©it√© des matrices de variance-covariance. Lorsqu'on a des √©chantillons √©quilibr√©s (m√™me effectif dans chaque modalit√© de la VI), ce n'est pas tr√®s grave et on peut poursuivre l'analyse. Si, en revanche, les √©chantillons sont d√©s√©qulibr√©s, on utilisera une autre statistique de test pour la MANOVA (trace de Pillai au lieu du lambda de Wilks).

## 2. R√©alisation de l'analyse

Pour faire une MANOVA, on cr√©e un mod√®le lin√©aire avec nos VD et nos VI avec la syntaxe suivante : `cbind(VD, ..., VD) ~ VI`. On applique ensuite la fonction `Manova()` sur le mod√®le qui en r√©sulte pour examiner les r√©sultats de l'analyse multivari√©e.

```{r}
#Construction du mod√®le
model <- lm(cbind(Sepal.Length, Petal.Length) ~ Species, iris2)

#R√©alisation de la MANOVA
  # Avec la trace de Pillai
Manova(model, test.statistic = "Pillai")

  #Avec le lambda de Wilks
Manova(model, test.statistic = "Wilks")
```

**Interpr√©tation** : On voit que le facteur `Species` est significatif, on peut donc conclure de l'effet de la variable sur la combinaison des variables d√©pendantes.

Pour rapporter cette analyse, on indiquera que la MANOVA a mis en √©vidence un effet significatif (F(4, 294) = 71.829, p \< .001)

**Passons aux tests post-hocs :**

1.  **Faire une ANOVA pour chaque VD, en abaissant le seuil de significativit√©.** Au lieu d'utiliser p \< .05, on utilise un seuil plus strict d√©termin√© par le nombre de tests. On divise .05 par le nombre de tests (ici 2) pour obtenir un nouveau seuil (ici, .05/2 = 0.25)

```{r}
# On utilise la fonction gather() pour rassembler les VD dans une m√™me colonne (et on ajoute une colonne pour sp√©cifier si c'est l'une ou l'autre)
grouped.data <- iris2 %>%
  gather(key = "variable", value = "value", Sepal.Length, Petal.Length) %>%
  group_by(variable)

# test ANOVA de Welch √† un facteur --> Non-homog√©n√©it√©
grouped.data %>% welch_anova_test(value ~ Species)

# test ANOVA √† un facteur --> Homog√©n√©it√©
grouped.data %>% anova_test(value ~ Species)


```

**Interpr√©tation** : Nos effets sont largement inf√©rieur √† notre seuil .025, nous pouvons donc conclure qu'il y a bien un effet principal de la variable `Species` sur chaque des VD test√©es.

2.  **R√©aliser les comparaisons deux √† deux pour chaque VD**.

```{r}
# Si Homog√©n√©it√© (pairwise t-test)
pwc1 <- iris2 %>%
  gather(key = "variables", value = "value", Sepal.Length, Petal.Length) %>%
  group_by(variables) %>%
  pairwise_t_test(value ~ Species) 
pwc1

# Si Non-Homog√©n√©it√© (Games-Howell)
pwc <- iris2 %>%
  gather(key = "variables", value = "value", Sepal.Length, Petal.Length) %>%
  group_by(variables) %>%
  games_howell_test(value ~ Species) 
pwc
```

**Interpr√©tation** : On a bien une diff√©rence significative entre toutes les modalit√©s de la variables `Species`, et ce, pour les deux VD test√©es. On rapportera les r√©sultats des deux tests post-hoc de la m√™me mani√®re que pour une ANOVA classique (indiquer les F des Anova univair√©es + les r√©sultats des comparaisons deux √† deux.

```{r}
pwc <- pwc %>% add_xy_position(x = "Species")

ggboxplot(iris2, x = "Species", y = c("Sepal.Length", "Petal.Length"), 
  merge = TRUE, palette = "jco") + 
  stat_pvalue_manual(pwc, hide.ns = TRUE, tip.length = 0, 
    step.increase = 0.1, step.group.by = "variables",
    color = "variables")
```
